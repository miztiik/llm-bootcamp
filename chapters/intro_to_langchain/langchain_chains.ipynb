{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "# Langchain Chains\n",
        "\n",
        "Chains refer to sequences of calls - whether to an LLM, a tool, or a data preprocessing step. Chains allow you to run multiple LangChain modules in conjunction. For example, using a chain, you can run a prompt and an LLM together, saving you from first formatting a prompt for an LLM model and executing it using the model in separate steps.\n",
        "\n",
        "LangChain supports three main types of chains:\n",
        "\n",
        "- Simple LLM Chain\n",
        "- Sequential Chain\n",
        "- Custom Chain\n",
        "\n",
        "Once you understand Chains, you can build powerful pipeline of chains in LangChain (hence the name). There are chains that can,\n",
        "\n",
        "- Calculates and run math operations.\n",
        "- Summarizes text.\n",
        "- Translates into a different language.\n",
        "- Come up with product names and slogans.\n",
        "\n",
        "In this notebook, we will use the `langchain` library to use pre-trained models for various NLP tasks. \n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/miztiik/llm-bootcamp/blob/main/chapters/intro_to_langchain/langchain_chains.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%capture\n",
        "# Comment the above line to see the installation logs\n",
        "\n",
        "# Install the dependencies\n",
        "!pip install -qU python-dotenv\n",
        "!pip install -qU langchain\n",
        "!pip install -qU langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "50dvxjqCFmhF"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load environment variables\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "\n",
        "load_dotenv(find_dotenv())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "C7RnyUOCJWmk"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import OpenAI\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = OpenAI(model_name=\"gpt-3.5-turbo-instruct\")\n",
        "llm_chat = ChatOpenAI(model_name=\"gpt-3.5-turbo-0125\", temperature=0.3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Simple LLM Chain\n",
        "\n",
        "  <img src=\"images/chains_02.png\" alt=\"Simple LLM Chain\" width=50%>\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'object': 'clothes', 'location': 'beach', 'text': '\\n\\n1. \"Sandy Chic\"\\n2. \"Coastal Threads\"\\n3. \"Beachy Boutique\"\\n4. \"Seaside Style Co.\"\\n5. \"Shoreline Fashions\"'}\n"
          ]
        }
      ],
      "source": [
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"object\", \"location\"],\n",
        "    template=\"Suggest 5 trendy names for {object} shop, located on {location}\",\n",
        ")\n",
        "\n",
        "chain = LLMChain(llm=llm, prompt=prompt)\n",
        "\n",
        "print(chain.invoke({\n",
        "    'object': \"clothes\",\n",
        "    'location': \"beach\"\n",
        "}))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Running Batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'object': 'icecream',\n",
              "  'location': 'beach',\n",
              "  'text': '\\n\\n1. \"Beach Creamery\"\\n2. \"Sandy Scoops\"\\n3. \"Coastal Cones\"\\n4. \"Seaside Swirls\"\\n5. \"Ocean\\'s Delight Ice Cream\"'},\n",
              " {'object': 'shoes',\n",
              "  'location': 'city',\n",
              "  'text': \"'s main street\\n\\n1. Sole Society\\n2. Street Chic Footwear\\n3. Urban Kicks\\n4. Main Street Shoes Co.\\n5. City Steps Boutique\"}]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain.batch([{'object': \"icecream\", 'location': \"beach\"},\n",
        "            {'object': \"shoes\", 'location': \"city\"}])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "chat_prompt_template = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"You are an expert technical writer.\"),\n",
        "        (\"user\", \"{input}\")\n",
        "    ]\n",
        ")\n",
        "chat_chain = LLMChain(llm=llm_chat, prompt=chat_prompt_template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input': 'Suggest 5 topics for a technical blog.', 'text': '1. Introduction to Machine Learning Algorithms\\n2. Best Practices for Secure Software Development\\n3. The Future of Artificial Intelligence in Healthcare\\n4. Exploring the Internet of Things (IoT) and its Applications\\n5. Deep Dive into Blockchain Technology and Cryptocurrencies'}\n"
          ]
        }
      ],
      "source": [
        "simple_chain_resp = chat_chain.invoke(\n",
        "    {\"input\": \"Suggest 5 topics for a technical blog.\"}\n",
        ")\n",
        "\n",
        "print(simple_chain_resp, end=\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sequential Chain\n",
        "\n",
        "A sequential chain allows you to execute multiple chains in a sequence. The `SimpleSequentialChain` object from the `langchain.chains module` enables you to create a sequential chain.\n",
        "\n",
        "  <img src=\"images/chains_04.png\" alt=\"Sequential Chain\" width=50%>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
            "\u001b[36;1m\u001b[1;3m\n",
            "\n",
            "\"Coastal Crush Juice Bar\" \u001b[0m\n",
            "\u001b[33;1m\u001b[1;3m\n",
            "\n",
            "\"Sip Up the Coastal Vibes at Coastal Crush Juice Bar!\"\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "{'input': 'beach', 'output': '\\n\\n\"Sip Up the Coastal Vibes at Coastal Crush Juice Bar!\"'}\n"
          ]
        }
      ],
      "source": [
        "from langchain.chains import SimpleSequentialChain\n",
        "\n",
        "prompt_1 = PromptTemplate(\n",
        "    input_variables=[\"location\"],\n",
        "    template=\"Suggest a trendy name for an juice bar, located on {location}\",\n",
        ")\n",
        "\n",
        "seq_chain_1 = LLMChain(llm=llm, prompt=prompt_1)\n",
        "\n",
        "prompt_2 = PromptTemplate(\n",
        "    input_variables=[\"location\"],\n",
        "    template=\"Write a catchy tag line for a for an juice bar, located on {location}\",\n",
        ")\n",
        "\n",
        "seq_chain_2 = LLMChain(llm=llm, prompt=prompt_2)\n",
        "\n",
        "seq_chain_resp = SimpleSequentialChain(\n",
        "    chains=[seq_chain_1, seq_chain_2], verbose=True)\n",
        "\n",
        "# Run the chain specifying only the input variable for the first chain.\n",
        "print(seq_chain_resp.invoke(\"beach\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Additional Reading\n",
        "\n",
        "- [LangChain Chains](https://python.langchain.com/docs/modules/chains)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyONM96f7/m0jUCD9c87+MQy",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
