{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize Google News Results with LangChain🦜🔗, Huggingface🤗 and Serper API\n",
    "\n",
    "## Overview\n",
    "\n",
    "Text summarization is the process of creating a shorter version of a text document while still preserving the most important information. This can be useful for a variety of purposes, such as quickly skimming a long document, getting the gist of an article, or sharing a summary with others. LLMs can be used to create summaries of news articles, research papers, technical documents, and other types of text.\n",
    "\n",
    "<img src=\"images/miztiik_text_summarization_01.png\" width=\"50%\"/>\n",
    "\n",
    "\n",
    "## Chunking Strategies for LLM Applications\n",
    "\n",
    "- **Stuffing method** - The `stuffing` method is the easiest way to summarize text by feeding the entire document to a large language model (LLM) in a single call. This method has both pros and cons.\n",
    "\n",
    "  - **Pros**:\n",
    "    - Only required a single call to the model, which can be faster than other methods that require multiple calls\n",
    "    - When summarizing text, the model has access to all the data at once, which can result in a better summary.\n",
    "  - **Cons**:\n",
    "    - Most models have a context length, and for large documents (or many documents) this will not work as it will result in a prompt larger than the context length.\n",
    "    - This method only works on smaller pieces of data and not suitable to large documents most of the time.\n",
    "\n",
    "- **MapReduce method** - It is a technique for summarizing large pieces of text by first summarizing smaller chunks of text and then combining those summaries into a single summary. The `MapReduce` method implements a multi-stage summarization. In LangChain, you can use `MapReduceDocumentsChain` as part of the `load_summarize_chain` method. What you need to do is setting `map_reduce` as `chain_type` of your chain.\n",
    "  - MapReduce with Overlapping Chunks method\n",
    "  - MapReduce with Rolling Summary method\n",
    "\n",
    "  <img src=\"images/miztiik_automation_docs_copilot_using_llm_rag_02.png\" width=\"50%\"/>\n",
    "\n",
    "\n",
    "As we do not know the length of the document, we will use the `map-reduce` method to summarize the news articles.\n",
    "\n",
    "In this notebook, we will try fetch the latest Google news using server API and use AI-generated summaries with LangChain LLM framework or huggingface transformers.\n",
    "\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/miztiik/llm-bootcamp/blob/main/chapters/text_summarization/news_summarization_with_hf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Comment the above line to see the installation logs\n",
    "\n",
    "# Install the dependencies\n",
    "!pip install -qU python-dotenv\n",
    "!pip install -qU langchain-core==0.1.23\n",
    "!pip install -qU langchain==0.1.6\n",
    "!pip install -qU langchain-community==0.0.19\n",
    "!pip install -qU langchain-openai\n",
    "!pip install -qU transformers --quiet\n",
    "!pip install -qU newspaper3k\n",
    "\n",
    "\n",
    "# langchain==0.1.6\n",
    "# langchain-community==0.0.19\n",
    "# langchain-core==0.1.23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not a good practice, but we will ignore warnings in this notebook, as tensor has deprecated some methods and will be removed in future versions.\n",
    "# https://github.com/pytorch/pytorch/issues/97207#issuecomment-1494781560\n",
    "import warnings\n",
    "\n",
    "# warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\", category=UserWarning, message=\"TypedStorage is deprecated\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update your `API_KEY` in the `.env` file. You can get the API keys from the following links. _Note: Some of the services may require you to have an account and some may charge you for usage_\n",
    "- [OpenAI API Key](https://platform.openai.com/account/api-keys)\n",
    "- [Hugging Face API Key](https://huggingface.co/settings/tokens)\n",
    "- [Serper API Key](https://serper.dev/api-key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"HF_TOKEN\"] = \"\"\n",
    "# os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"\"\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "# os.environ[\"SERPER_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# To specify a particular model refer to the OpenAI documentation - https://platform.openai.com/docs/models\n",
    "# Completions Model: https://platform.openai.com/docs/models/completions\n",
    "# Chat Model: https://platform.openai.com/docs/models/completions\n",
    "\n",
    "llm = OpenAI()\n",
    "llm_chat = ChatOpenAI(model_name=\"gpt-3.5-turbo-0125\", temperature=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import NewsURLLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Serper API** - [Sign up](https://serper.dev/signup?ref=miztiik) for an account with Serper, or log in if you already have an account, and create an API key. Serper offers a generous free tier; as you consume the API, the dashboard will populate with the requests and remaining credits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "search = GoogleSerperAPIWrapper(\n",
    "    type=\"news\", tbs=\"qdr:d60\", serper_api_key=os.getenv(\"SERPER_API_KEY\")\n",
    ")\n",
    "\n",
    "news_search_query = \"hackernoon ai gpt\"\n",
    "news_results = search.results(news_search_query, num_results=5)\n",
    "\n",
    "if news_results.get(\"news\") is None:\n",
    "    print(\"No results found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "print(len(news_results[\"news\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title:5 Practical Use Cases for GPT-4 Vision AI Model\n",
      "link:https://hackernoon.com/5-practical-use-cases-for-gpt-4-vision-ai-model\n",
      "snippet:The GPT-4 Vision AI model has made significant strides in transforming how we approach daily tasks and hobbies.\n",
      "date:2 weeks ago\n",
      "source:HackerNoon\n",
      "imageUrl:https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTnUV_PEYYTI8Fy78AzKEjicg_EMGBf07euk3qxG_nrzsipreWusFOI3KaoMQ&s\n",
      "position:1\n"
     ]
    }
   ],
   "source": [
    "for i in news_results[\"news\"][0]:\n",
    "    print(f\"{i}:{news_results['news'][0][i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit how many news articles to process\n",
    "num_results = min(5, len(news_results[\"news\"]))\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\n",
    "        \"\\n\\n\",\n",
    "        \"\\n\",\n",
    "    ],\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=100,\n",
    ")\n",
    "\n",
    "# For each news article, load the contents\n",
    "for index, news_item in enumerate(news_results[\"news\"]):\n",
    "    loader = NewsURLLoader(urls=[news_item.get(\"link\")])\n",
    "    contents = loader.load()\n",
    "    if contents:\n",
    "        news_results[\"news\"][index][\"article\"] = contents\n",
    "        # Make the docs to fit model input size\n",
    "        news_results[\"news\"][index][\"split_article\"] = text_splitter.create_documents(\n",
    "            [contents[0].page_content]\n",
    "        )\n",
    "    else:\n",
    "        print(f\"Failed to load {news_item['link']}, removed from results.\\n\")\n",
    "        news_results[\"news\"].pop(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "print(len(news_results[\"news\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': '5 Practical Use Cases for GPT-4 Vision AI Model', 'link': 'https://hackernoon.com/5-practical-use-cases-for-gpt-4-vision-ai-model', 'snippet': 'The GPT-4 Vision AI model has made significant strides in transforming how we approach daily tasks and hobbies.', 'date': '2 weeks ago', 'source': 'HackerNoon', 'imageUrl': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTnUV_PEYYTI8Fy78AzKEjicg_EMGBf07euk3qxG_nrzsipreWusFOI3KaoMQ&s', 'position': 1, 'article': [Document(page_content='356 reads\\n\\n5 Practical Use Cases for GPT-4 Vision AI Model\\n\\nFebruary 3rd 2024 4 m by @ codevore 356 reads\\n\\nEN', metadata={'title': '5 Practical Use Cases for GPT-4 Vision AI Model', 'link': 'https://hackernoon.com/5-practical-use-cases-for-gpt-4-vision-ai-model', 'authors': [], 'language': 'en', 'description': 'The GPT-4 Vision AI model has made significant strides in transforming how we approach daily tasks and hobbies.', 'publish_date': None})], 'split_article': [Document(page_content='356 reads\\n\\n5 Practical Use Cases for GPT-4 Vision AI Model\\n\\nFebruary 3rd 2024 4 m by @ codevore 356 reads\\n\\nEN')]}\n",
      "\u001b[32m-----\u001b[0m\n",
      "{'title': 'Why Open Source Language Models Are True “Open AI”', 'link': 'https://hackernoon.com/why-open-source-language-models-are-true-open-ai', 'snippet': \"H2O.ai's Danube is the latest in a series of open-source language models.\", 'date': '2 weeks ago', 'source': 'HackerNoon', 'imageUrl': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcT37P8Wg1-8K-QBfYzCELxdkN3r2bxeQJd_27fszS3OLD2BLMZBTZjFaBbMvQ&s', 'position': 2, 'article': [Document(page_content='Trending # 4\\n\\nWhy Open Source Language Models Are True “Open AI”\\n\\nFebruary 5th 2024 4 m by @ FrederikBussler Trending # 4\\n\\nEN', metadata={'title': 'Why Open Source Language Models Are True “Open AI”', 'link': 'https://hackernoon.com/why-open-source-language-models-are-true-open-ai', 'authors': [], 'language': 'en', 'description': \"H2O.ai's Danube is the latest in a series of open-source language models.\", 'publish_date': None})], 'split_article': [Document(page_content='Trending # 4\\n\\nWhy Open Source Language Models Are True “Open AI”\\n\\nFebruary 5th 2024 4 m by @ FrederikBussler Trending # 4\\n\\nEN')]}\n",
      "\u001b[32m-----\u001b[0m\n",
      "{'title': '100 Days of AI Day 7: Building Your Own ChatGPT with Langchain', 'link': 'https://hackernoon.com/100-days-of-ai-day-7-building-your-own-chatgpt-with-langchain', 'snippet': 'Previous Piece — 100 Days of AI Day 6: Retrieval Techniques and Their Use Cases. One of the use cases everyone wanted to see after ChatGpt broke out to the...', 'date': '1 month ago', 'source': 'HackerNoon', 'imageUrl': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTe-_eGczdfloc7QVfzpJn87BjNw25vaT0itfxaatukcntXhNWnEkV9XDmEFQ&s', 'position': 3, 'article': [Document(page_content=\"100 Days of AI Day 7: Building Your Own ChatGPT with Langchain\\n\\nToo Long; Didn't Read Discover the groundbreaking process of building a retrieval augmented generation (RAG) chatbot for Azure Files using Langchain and OpenAI integration. From loading PDF data to employing embeddings and vector databases, the step-by-step guide showcases the power of RAG in creating efficient and context-aware chatbot experiences. Plus, explore three potential AI product ideas in the evolving landscape of conversational AI.\", metadata={'title': '100 Days of AI Day 7: Building Your Own ChatGPT with Langchain', 'link': 'https://hackernoon.com/100-days-of-ai-day-7-building-your-own-chatgpt-with-langchain', 'authors': [], 'language': 'en', 'description': 'Step by step process on how to build chat with you data application using Open AI & LangChain in Python.', 'publish_date': None})], 'split_article': [Document(page_content=\"100 Days of AI Day 7: Building Your Own ChatGPT with Langchain\\n\\nToo Long; Didn't Read Discover the groundbreaking process of building a retrieval augmented generation (RAG) chatbot for Azure Files using Langchain and OpenAI integration. From loading PDF data to employing embeddings and vector databases, the step-by-step guide showcases the power of RAG in creating efficient and context-aware chatbot experiences. Plus, explore three potential AI product ideas in the evolving landscape of conversational AI.\")]}\n",
      "\u001b[32m-----\u001b[0m\n",
      "{'title': 'Top 10 AI Trends of 2024: How AI Transforms Everything', 'link': 'https://hackernoon.com/top-10-ai-trends-of-2024-how-ai-transforms-everything', 'snippet': 'Artificial Intelligence (AI) is transforming industries and creating new opportunities at the speed of light. From AI-generated video to its integration...', 'date': '1 month ago', 'source': 'HackerNoon', 'imageUrl': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQT2D6D7bOLnsRtGSeZ2RO0W6iSl2BkJYp9RoEO1LxaUfhE4ZZ-oWQg30SzoA&s', 'position': 4, 'article': [Document(page_content=\"Receive Stories from @ sergey-baloyan\\n\\nSUBSCRIBE SUBSCRIBE TO RECEIVE THIS WRITER'S CONTENT STRAIGHT TO YOUR INBOX!\", metadata={'title': 'Top 10 AI Trends of 2024: How AI Transforms Everything', 'link': 'https://hackernoon.com/top-10-ai-trends-of-2024-how-ai-transforms-everything', 'authors': [], 'language': 'en', 'description': 'Explore how AI is causing uproar across industries and disturbs the world of work.', 'publish_date': None})], 'split_article': [Document(page_content=\"Receive Stories from @ sergey-baloyan\\n\\nSUBSCRIBE SUBSCRIBE TO RECEIVE THIS WRITER'S CONTENT STRAIGHT TO YOUR INBOX!\")]}\n",
      "\u001b[32m-----\u001b[0m\n",
      "{'title': 'How NVIDIA’s Latest AI Creations at CES2024 Redefine How We Live, Work And Play', 'link': 'https://hackernoon.com/how-nvidias-latest-ai-creations-at-ces2024-redefine-how-we-live-work-and-play', 'snippet': 'NVIDIA revealed the Tensor RT LLM library, turbocharging the performance of models like Llama 2 and Mistol running on Windows.', 'date': '1 month ago', 'source': 'HackerNoon', 'imageUrl': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRGa7UVhhB9hURbvB-8NMccT5EHG4twkfkvR15i8hOIahMaSvCMJVF5dwtaFQ&s', 'position': 5, 'article': [Document(page_content=\"Too Long; Didn't Read\\n\\nCompany Mentioned\\n\\nThe annual CES tech extravaganza is where the biggest industry players put their best ideas on display. NVIDIA revealed the Tensor RT LLM library, turbocharging the performance of models like Llama 2 and Mistol running on Windows. The company's robotics platform, NVIDIA Isaac, brings the massive potential of generative AI to robotics.\", metadata={'title': 'How NVIDIA’s Latest AI Creations at CES2024 Redefine How We Live, Work And Play', 'link': 'https://hackernoon.com/how-nvidias-latest-ai-creations-at-ces2024-redefine-how-we-live-work-and-play', 'authors': [], 'language': 'en', 'description': 'NVIDIA revealed the Tensor RT LLM library, turbocharging the performance of models like Llama 2 and Mistol running on Windows.', 'publish_date': None})], 'split_article': [Document(page_content=\"Too Long; Didn't Read\\n\\nCompany Mentioned\\n\\nThe annual CES tech extravaganza is where the biggest industry players put their best ideas on display. NVIDIA revealed the Tensor RT LLM library, turbocharging the performance of models like Llama 2 and Mistol running on Windows. The company's robotics platform, NVIDIA Isaac, brings the massive potential of generative AI to robotics.\")]}\n",
      "\u001b[32m-----\u001b[0m\n",
      "{'title': '10 Tips to Take Your ChatGPT Prompts to the Next Level', 'link': 'https://hackernoon.com/10-tips-to-take-your-chatgpt-prompts-to-the-next-level', 'snippet': \"Welcome to the awesome world of AI, where chatting with a computer program like ChatGPT isn't just cool; it's like unlocking a superpower!\", 'date': '3 weeks ago', 'source': 'HackerNoon', 'imageUrl': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcStaztAlRQW50-nLZWKc-De11nhCplFF8QBshuJT7vBo9I7-auSVCEh832ulA&s', 'position': 6, 'article': [Document(page_content='Trending # 9\\n\\n10 Tips to Take Your ChatGPT Prompts to the Next Level\\n\\nJanuary 30th 2024 11 m by @ morganmsk Trending # 9\\n\\nEN', metadata={'title': '10 Tips to Take Your ChatGPT Prompts to the Next Level', 'link': 'https://hackernoon.com/10-tips-to-take-your-chatgpt-prompts-to-the-next-level', 'authors': [], 'language': 'en', 'description': 'Maximize your ChatGPT experience with 10 expert tips for crafting precise prompts and queries, enhancing interaction quality.', 'publish_date': None})], 'split_article': [Document(page_content='Trending # 9\\n\\n10 Tips to Take Your ChatGPT Prompts to the Next Level\\n\\nJanuary 30th 2024 11 m by @ morganmsk Trending # 9\\n\\nEN')]}\n",
      "\u001b[32m-----\u001b[0m\n",
      "{'title': 'The Times v. Microsoft/OpenAI: Unauthorized Reproductions of Times Works in GPT Models (11)', 'link': 'https://hackernoon.com/the-times-v-microsoftopenai-unauthorized-reproductions-of-times-works-in-gpt-models-11', 'snippet': \"'The Times v. Microsoft/OpenAI: Unauthorized Reproductions of Times Works in GPT Models (11)' via HackerNoon AI Image Generator.\", 'date': '1 month ago', 'source': 'HackerNoon', 'imageUrl': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTavtY9-b6kQzPRYqzHWVvrRnMvBI45eRwcB5zgYiQOi--F08MjzNff5H0New&s', 'position': 7, 'article': [Document(page_content='Legal PDF\\n\\nLegal PDFs of important tech court cases are far too inaccessible for the average reader... until now.', metadata={'title': 'The Times v. Microsoft/OpenAI: Unauthorized Reproductions of Times Works in GPT Models (11)', 'link': 'https://hackernoon.com/the-times-v-microsoftopenai-unauthorized-reproductions-of-times-works-in-gpt-models-11', 'authors': [], 'language': 'en', 'description': 'As further evidence of being trained using unauthorized copies of Times Works, the GPT LLMs themselves have “memorized” copies of many of those same works encod', 'publish_date': None})], 'split_article': [Document(page_content='Legal PDF\\n\\nLegal PDFs of important tech court cases are far too inaccessible for the average reader... until now.')]}\n",
      "\u001b[32m-----\u001b[0m\n",
      "{'title': 'The Times v. Microsoft/OpenAI: A Business Model Based on Mass Copyright Infringement (8)', 'link': 'https://hackernoon.com/the-times-v-microsoftopenai-a-business-model-based-on-mass-copyright-infringement-8', 'snippet': 'OpenAI started with $1 billion in seed money from its founders, a group of some of the wealthiest technology entrepreneurs and investors and companies.', 'date': '1 month ago', 'source': 'HackerNoon', 'imageUrl': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRYoZi2cSUY52n5G12Tl1mXU2R6oconcx6_upQSg4wuhA4ztJuz7CzgfIFuig&s', 'position': 8, 'article': [Document(page_content='Legal PDF\\n\\nLegal PDFs of important tech court cases are far too inaccessible for the average reader... until now.', metadata={'title': 'The Times v. Microsoft/OpenAI: A Business Model Based on Mass Copyright Infringement (8)', 'link': 'https://hackernoon.com/the-times-v-microsoftopenai-a-business-model-based-on-mass-copyright-infringement-8', 'authors': [], 'language': 'en', 'description': 'OpenAI started with $1 billion in seed money from its founders, a group of some of the wealthiest technology entrepreneurs and investors and companies', 'publish_date': None})], 'split_article': [Document(page_content='Legal PDF\\n\\nLegal PDFs of important tech court cases are far too inaccessible for the average reader... until now.')]}\n",
      "\u001b[32m-----\u001b[0m\n",
      "{'title': 'PrivateGPT for Book Summarization: Testing and Ranking Configuration Variables', 'link': 'https://hackernoon.com/privategpt-for-book-summarization-testing-and-ranking-configuration-variables', 'snippet': 'I started to summarize a dozen books by hand and found it was going to take me weeks for each summary. Then I remembered about this AI revolution happening...', 'date': '1 month ago', 'source': 'HackerNoon', 'imageUrl': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRJQTHWBd2NWXIzbdGelrxdfX-7nGhapFVOpZBP7NH6MDfQShk4hGxxoNBb9A&s', 'position': 9, 'article': [Document(page_content=\"Too Long; Didn't Read\\n\\nPeople Mentioned\\n\\nThere are many variables when implementing large language models. Lets test and refine our processes for summarizing books using PrivateGPT, powered by NVIDIA RTX 3060 12GB.\", metadata={'title': 'PrivateGPT for Book Summarization: Testing and Ranking Configuration Variables', 'link': 'https://hackernoon.com/privategpt-for-book-summarization-testing-and-ranking-configuration-variables', 'authors': [], 'language': 'en', 'description': 'Summarizing books with local llm. My methods for testing and optimizing the use of PrivateGPT for book summaries.', 'publish_date': None})], 'split_article': [Document(page_content=\"Too Long; Didn't Read\\n\\nPeople Mentioned\\n\\nThere are many variables when implementing large language models. Lets test and refine our processes for summarizing books using PrivateGPT, powered by NVIDIA RTX 3060 12GB.\")]}\n",
      "\u001b[32m-----\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "for i in news_results[\"news\"]:\n",
    "    print(i)\n",
    "    print(f\"\\033[32m-----\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarization with Open AI Models\n",
    "\n",
    "<img src=\"images/miztiik_text_summarization_02.png\" width=\"50%\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16k is the max input length for GPT-3.5\n",
    "# num_tokens_first_doc = llm.get_num_tokens(\n",
    "#     news_results[\"news\"][1][\"contents\"][0].page_content\n",
    "# )\n",
    "\n",
    "map_prompt = \"\"\" Write a concise summary of the following:\n",
    "\"{text}\"\n",
    "CONCISE SUMMARY:\n",
    "\"\"\"\n",
    "map_prompt_template = PromptTemplate(\n",
    "    template=map_prompt,\n",
    "    input_variables=[\"text\"]\n",
    ")\n",
    "\n",
    "combine_prompt = \"\"\" Write a concise summary of the following text delimited by triple backquotes.\n",
    "```{text}```\n",
    "CONCISE SUMMARY:\n",
    "\"\"\"\n",
    "combine_prompt_template = PromptTemplate(\n",
    "    template=combine_prompt,\n",
    "    input_variables=[\"text\"]\n",
    ")\n",
    "\n",
    "oai_chain = load_summarize_chain(\n",
    "    llm=llm,\n",
    "    chain_type=\"map_reduce\",\n",
    "    map_prompt=map_prompt_template,\n",
    "    combine_prompt=combine_prompt_template,\n",
    "    # Uncomment verbose=True if you want to see the prompts being used\n",
    "    # verbose=True\n",
    ")\n",
    "\n",
    "for news_item in news_results[\"news\"][:num_results]:\n",
    "    if news_item.get(\"article\"):\n",
    "        print(\n",
    "            f\"Summarizing article: {news_item['title']} - {news_item['link']}\\n\")\n",
    "        news_item[\"oai_summary\"] = oai_chain.invoke(news_item[\"split_article\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us take a look at the summaries generated by the `map-reduce` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in news_results[\"news\"][:num_results]:\n",
    "    if i.get(\"article\"):\n",
    "        print(\n",
    "            f\"\\nTitle: {i['title']}\\nLink: {i['link']}\\nSummary: \\033[32m{i['oai_summary']['output_text']}\\033[0m\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "The summarization is reads like written by a person, does a good job of capturing the main points of the article. The summary is coherent and reads well. As OpenAI continues to improve their models, we can expect the quality of the summaries to improve as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarization with Huggingface Open Source Hosted Models with LangChain\n",
    "\n",
    "<img src=\"images/miztiik_text_summarization_03.png\" width=\"50%\"/>\n",
    "\n",
    "We will try a variety of model and see how they perform. We will use,\n",
    "- `google/flan-t5-xxl`\n",
    "- `facebook/bart-large-cnn`\n",
    "- `sshleifer/distilbart-cnn-12-6`\n",
    "- `Falconsai/text_summarization`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarization with Hugging Face hosted models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing article: Billionaire Investor Chase Coleman Has 46% of His Portfolio Invested in 5 Brilliant Artificial Intelligence (AI) Growth ... - https://finance.yahoo.com/news/billionaire-investor-chase-coleman-46-124000295.html\n",
      "\n",
      "Summarizing article: BL Nasscom Roundtable: Generative AI to drive next phase of growth for Indian IT - https://www.thehindubusinessline.com/news/bl-nasscom-roundtable-generative-ai-to-drive-next-phase-of-growth-for-indian-it/article67860933.ece\n",
      "\n",
      "Summarizing article: 2 Artificial Intelligence Stocks You Can Buy and Hold for the Next Decade - http://www.msn.com/en-us/money/topstocks/2-artificial-intelligence-stocks-you-can-buy-and-hold-for-the-next-decade/ar-BB1irg1B?apiversion=v2&noservercache=1&domshim=1&renderwebcomponents=1&wcseo=1&batchservertelemetry=1&noservertelemetry=1\n",
      "\n",
      "Summarizing article: India's Strategic AI Embrace: Fostering Growth and Ethical Use in the Global Race - https://bnnbreaking.com/tech/indias-strategic-ai-embrace-fostering-growth-and-ethical-use-in-the-global-race\n",
      "\n",
      "Summarizing article: Google expands AI development with new hub in France - https://coingeek.com/google-expands-ai-development-with-new-hub-in-france/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.llms.huggingface_hub import HuggingFaceHub\n",
    "\n",
    "hf_hub_llm = HuggingFaceHub(\n",
    "    repo_id=\"google/flan-t5-xxl\",\n",
    "    model_kwargs={\"temperature\": 0.3, \"max_length\": 512},\n",
    "    # repo_id=\"philschmid/bart-large-cnn-samsum\", model_kwargs={\"temperature\": 0.3, \"max_length\": 256}\n",
    "    # repo_id=\"mistralai/Mistral-7B-v0.1\", model_kwargs={\"temperature\": 0.3, \"max_length\": 512}\n",
    ")\n",
    "\n",
    "hf_hub_chain = load_summarize_chain(\n",
    "    llm=hf_hub_llm,\n",
    "    chain_type=\"map_reduce\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# run chain\n",
    "for news_item in news_results[\"news\"][:num_results]:\n",
    "    if news_item.get(\"article\"):\n",
    "        print(\n",
    "            f\"Summarizing article: {news_item['title']} - {news_item['link']}\\n\")\n",
    "        news_item[\"hf_hub_summary\"] = hf_hub_chain.invoke(\n",
    "            news_item[\"split_article\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Title: Billionaire Investor Chase Coleman Has 46% of His Portfolio Invested in 5 Brilliant Artificial Intelligence (AI) Growth ...\n",
      "Link: https://finance.yahoo.com/news/billionaire-investor-chase-coleman-46-124000295.html\n",
      "Summary: \u001b[32mThe Motley Fool's Billionaire Investor Chase Coleman has 46% of his portfolio invested in 5 brilliant artificial intelligence (AI) growth stocks. Here's why he likes them so much.\u001b[0m\n",
      "\n",
      "Title: BL Nasscom Roundtable: Generative AI to drive next phase of growth for Indian IT\n",
      "Link: https://www.thehindubusinessline.com/news/bl-nasscom-roundtable-generative-ai-to-drive-next-phase-of-growth-for-indian-it/article67860933.ece\n",
      "Summary: \u001b[32mThe Indian IT industry is in a state of flux, with new players entering the market, and old ones exiting.\u001b[0m\n",
      "\n",
      "Title: 2 Artificial Intelligence Stocks You Can Buy and Hold for the Next Decade\n",
      "Link: http://www.msn.com/en-us/money/topstocks/2-artificial-intelligence-stocks-you-can-buy-and-hold-for-the-next-decade/ar-BB1irg1B?apiversion=v2&noservercache=1&domshim=1&renderwebcomponents=1&wcseo=1&batchservertelemetry=1&noservertelemetry=1\n",
      "Summary: \u001b[32mThe spokesman for the United Nations Development Fund for Women (UNIFEM), which is implementing the project, said that the project is aimed at promoting gender equality and women's empowerment in the developing world. \"\"\u001b[0m\n",
      "\n",
      "Title: India's Strategic AI Embrace: Fostering Growth and Ethical Use in the Global Race\n",
      "Link: https://bnnbreaking.com/tech/indias-strategic-ai-embrace-fostering-growth-and-ethical-use-in-the-global-race\n",
      "Summary: \u001b[32mThe triumvirate of open data, open compute, and open models is central to India's AI strategy.\u001b[0m\n",
      "\n",
      "Title: Google expands AI development with new hub in France\n",
      "Link: https://coingeek.com/google-expands-ai-development-with-new-hub-in-france/\n",
      "Summary: \u001b[32mGoogle has confirmed plans to establish a research hub for artificial intelligence in France, continuing a trend for leading tech firms to set up innovation teams in European cities. Google is establishing its first AI research lab in France, a move that will help the company expand its AI research efforts in Europe. To achieve these lofty ambitions, French government agencies are softening their stance toward global AI developers to stimulate growth in the local ecosystem.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "for i in news_results[\"news\"][:num_results]:\n",
    "    if i.get(\"article\"):\n",
    "        print(\n",
    "            f\"\\nTitle: {i['title']}\\nLink: {i['link']}\\nSummary: \\033[32m{i['hf_hub_summary']['output_text']}\\033[0m\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarization with Huggingface Open Source Local Models with LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bart_model_max_model_length:1024\n"
     ]
    }
   ],
   "source": [
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load the model and tokenizer\n",
    "\n",
    "bart_model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "bart_tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "\n",
    "print(f\"bart_model_max_model_length:{bart_tokenizer.model_max_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing article: A Look Into the Global AI Regulatory Landscape - https://www.project-disco.org/innovation/a-look-into-the-global-ai-regulatory-landscape/\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new MapReduceDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m Write a concise summary of the following:\n",
      "\"A Look Into the Global AI Regulatory Landscape\n",
      "\n",
      "Artificial intelligence (AI) is a highly versatile technology. From one program’s application in a pastry shop to its later employment in detecting cancer cells, AI is truly integrating itself into many diverse aspects of our world. However, the rapid rise of AI has also intensified the need for governments to strengthen their capabilities to understand, leverage, operate, and when it calls for it, regulate this technology. As a result, there is a growing regulatory tension between different jurisdictions, which includes the development of comprehensive or sector-specific legislation and voluntary guidelines and standards.\"\n",
      "CONCISE SUMMARY:\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m Write a concise summary of the following:\n",
      "\"In June of last year, Josh Landau discussed AI legislation in the U.S. and the effects it could have on the industry. And in late October, the Biden-Harris Administration finally released its long anticipated Executive Order (EO) on AI. In the wake of the NIST Risk Management Framework, as well as the recently released EO and the Blueprint for an AI Bill of Rights, it appears the White House is taking a thoughtful, risk-based approach to regulating AI. While the U.S. is taking a cautiously optimistic stance when it comes to AI, other regimes are moving forward with more broad and burdensome proposals that could very well hinder this burgeoning technology’s development. In Europe, EU member states recently approved final wording of the AI Act. However, while the EU sees the potential of AI through its own competitive AI ecosystem, many of the new AI rules remain unclear and could obstruct the development and roll-out of innovative AI applications across Europe.\"\n",
      "CONCISE SUMMARY:\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m Write a concise summary of the following:\n",
      "\"Moreover, Europe and the U.S. are by no means the only two players in this regulatory rivalry. The UK, Canada, Israel, and many other countries and territories are all pursuing some form of AI regulation.\n",
      "\n",
      "U.S.\n",
      "\n",
      "The Biden-Harris Administration is acutely aware of this technology and growing regulatory rivalries, and took action on the matter before the newest EO by publishing the Blueprint for an AI Bill of Rights and issuing an EO Advancing Racial Equity and Support for Underserved Communities Through the Federal Government. The White House EO on AI does raise some concerns, but it also represents a positive step forward in AI governance and promises a bright future.\"\n",
      "CONCISE SUMMARY:\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m Write a concise summary of the following:\n",
      "\"\n",
      "The EO on AI has quite a broad scope, directing a number of actions to maximize AI’s potential. Among its many provisions, it proposes new privacy, safety, and security standards, assigns agencies to develop and share reports and guidelines for the responsible use of AI, and encourages attracting global talent. Commenting on the Biden Administration’s EO on AI, Senators Schumer and Young announced they are also working on legislation that would build upon the Executive Order from the President. Furthermore, the White House recently announced that “top federal officials working to carry out the AI EO say their agencies have completed all of the 90-day actions asked of them.” And most recently, at State of the Net 2024, Congressional AI Caucus Vice Chair Don Beyer said that there is a bipartisan plan from House leaders to create an informal AI task force and pass several AI bills in 2024. These efforts spotlight the fast pace officials are moving to keep pace with the growth of the technology.\"\n",
      "CONCISE SUMMARY:\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m Write a concise summary of the following:\n",
      "\"In addition to the federal government, many states are pursuing AI legislation as well. States are introducing legislation to regulate AI in a number of sectors, with pieces of legislation often falling into one of five key categories:\n",
      "\n",
      "Establishing AI development standards; Labeling various content generated by AI applications; Regulating suggestive algorithmic feeds Pursuing studies or creating task forces to determine how best to regulate AI; and Enhancing oversight of algorithmically-informed decision-making across broad sectors via comprehensive AI Bills of Rights.\"\n",
      "CONCISE SUMMARY:\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m Write a concise summary of the following:\n",
      "\"\n",
      "The focus of these pieces of legislation ranges from protecting children online to ensuring the integrity of our elections. Several states are taking an especially close look at this topic. For example, last year Connecticut Senator James Maroney led a multi-state AI task force, which expanded to include lawmakers from state legislatures across the country. Last year, California, which tends to be among the first states to propose regulations on technology, began contemplating legislation such as AB 331, regarding automated decision tools. Now, the California legislature has over ten proposals centered on AI, and Governor Gavin Newsom signed an executive order “to study the development, use, and risks of artificial intelligence (AI) technology throughout the state and to develop a deliberate and responsible process for evaluation and deployment of AI within state government.” As most states are only at the beginning of 2024 legislative sessions, the legislative landscape at the state level is likely to continue to evolve before most sessions adjourn this summer.\"\n",
      "CONCISE SUMMARY:\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m Write a concise summary of the following:\n",
      "\"To overregulate this sector risks AI evolution stagnating in the United States. AI governance must achieve a balance that ensures the safety and security of citizens while promoting innovation and competition, advancing U.S. AI leadership across the world.\n",
      "\n",
      "EU\"\n",
      "CONCISE SUMMARY:\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m Write a concise summary of the following:\n",
      "\"EU\n",
      "\n",
      "Besides the U.S., another regulatory model contributing to the current landscape is the European Union’s AI Act. EU member states recently approved final wording of the AI Act, which was proposed by the European Commission three years ago. The AI Act aims to create risk-based rules on how AI is developed and used in the EU. Certain practices deemed unacceptable will be entirely prohibited, while AI systems deemed high-risk will be subject to strict requirements. The AI Act deviates from its risk-based approach by imposing strict obligations on developers of foundation models, powerful models underpinning all kinds of different applications, including generative AI application. The vote for the Act’s formal adoption could occur in March or April.\"\n",
      "CONCISE SUMMARY:\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m Write a concise summary of the following:\n",
      "\"Boniface de Champris has previously addressed the European AI Act, noting the rules lack clarity and could seriously damage Europe’s economy. Despite improvements to the final text, many of the new AI rules remain unclear and could slow down the development and roll-out of innovative AI applications in Europe. Europe has a highly competitive AI ecosystem; the Act’s proper implementation will therefore be crucial to ensuring that AI rules do not overburden companies in their quest to innovate and compete in a thriving, highly dynamic market.\n",
      "\n",
      "UK\"\n",
      "CONCISE SUMMARY:\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m Write a concise summary of the following:\n",
      "\"UK\n",
      "\n",
      "The UK also aspires to hold a positive, leadership role in artificial intelligence. Michelle Donelan, Secretary of State at the Department for Science, Innovation and Technology (DSIT), told a House of Lords Committee that the Government has taken a “pro-innovation” approach to AI, addressing risks transparently rather than turning away from AI. She pointed to steps to that end including the AI Opportunities Forum, the AI Safety Summit and international partnerships such as a Memorandum of Understanding with Canada around compute capacity.\n",
      "\n",
      "The UK does not yet have a landmark AI law. However Donelan and other Ministers point to the Summit and the AI Safety Institute as firsts that show the UK is at the cutting edge in addressing emerging risks. Instead of setting out new legislation, or creating new regulators, the intent is to use existing legislation and existing regulatory bodies to respond to diverse risks as they emerge.\"\n",
      "CONCISE SUMMARY:\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m Write a concise summary of the following:\n",
      "\"However this does not mean there are no challenges in the UK. The Competition and Markets Authority is being given extensive new powers to intervene in digital markets and, if the right checks and balances are not included, there is a risk that premature or overly-broad regulation might inhibit the development of new services with new business models that could benefit consumers. While the UK does have fair dealing, without a more general provision akin to the “fair use” doctrine in the U.S., UK copyright law depends on formal changes which are struggling to move forward.\"\n",
      "CONCISE SUMMARY:\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m Write a concise summary of the following:\n",
      "\"More generally, it is still not clear whether the UK’s intention to provide a flexible, pro-innovation approach to AI will survive a slow accretion of restrictions from different regulations and regulators, or pressure for a larger comprehensive regulatory response. Some parliamentarians are conscious of the risks here. Baroness Stowell, Chairman of the House of Lords Communications and Digital Committee, warned that “we need to be proportionate and practical” in addressing risks and “not miss out on opportunities”. She noted that excessive caution might “exclude smaller players from developing AI services.”\n",
      "\n",
      "Canada\"\n",
      "CONCISE SUMMARY:\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m Write a concise summary of the following:\n",
      "\"Canada\n",
      "\n",
      "In September, Canada’s Minister of Innovation, Science and Industry, François-Philippe Champagne, voiced an ambition for Canada to be the first country to have AI regulations in place to “inspire the rest of the world.” Although that goal is now unreachable after the EU’s agreement on the AI Act, Canada’s Parliament continues its work to advance what it hopes would be a template for global AI regulation in Bill C-27, the Digital Charter Implementation Act, which itself has been under consideration since June 2022.\n",
      "\n",
      "Bill C-27, however, introduces new challenges and concerns. The bill is split into two parts—the first section overhauls the privacy rules in Canada, and the second incorporates the Artificial Intelligence and Data Act, which seeks to establish “common requirements, applicable across Canada, for the design, development and use” of AI systems.\"\n",
      "CONCISE SUMMARY:\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m Write a concise summary of the following:\n",
      "\"Artificial intelligence systems are defined with a broad brush as any technological system that, “autonomously or partly autonomously, processes data related to human activities through the use of a genetic algorithm, a neural network, machine learning or another technique in order to generate content or make decisions, recommendations or predictions.” Many of its definitions — such as “high-impact AI systems” or “person responsible” — are left opaque or undefined, leaving interpretations that could lead to disclosure of trade secrets, excessive punishments for innovators, and restrictions on services trade for online programs.\"\n",
      "CONCISE SUMMARY:\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m Write a concise summary of the following:\n",
      "\"Even more concerning, in October 2023, the government stated its intent to include AI used in the “moderation of content that is found on an online communications platform, including a search engine and a social media service” or the “prioritization of the presentation of such content” under “high-impact” AI systems. This unique inclusion is notable, as it could undermine online services providers’ activity in the Canadian market given the potential broad-sweeping applicability of such a category.\n",
      "\n",
      "Bill C-27 is still being studied by the House of Commons Standing Committee on Industry and Technology—once it is voted out of committee, it will require approval from the House of Commons and the Senate (which would need to hold a committee process of its own and could undergo further amendment) before it can receive Royal Assent.\"\n",
      "CONCISE SUMMARY:\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m Write a concise summary of the following:\n",
      "\"The lack of clarity in Bill C-27 and its sweeping application raises concerns that this legislation will introduce an overly burdensome regulatory framework, which would in turn endanger interoperability across the continent for services subject to its obligations. Some of the companies leading innovations in AI warned the Canadian Parliament of these concerns earlier this month, with Meta’s representative telling the Committee that the law could result in the company being unable to roll out certain services and products in Canada. As such, if it remains as is, Bill C-27 could undermine the development of a growing and innovative field by creating regulatory uncertainty and a marketplace hostile to innovative practices.\n",
      "\n",
      "Conclusion\"\n",
      "CONCISE SUMMARY:\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m Write a concise summary of the following:\n",
      "\"Conclusion\n",
      "\n",
      "The pressures and potential of AI are pushing many regulators forward in a race to regulate, often due to ill-defined and unproven fears of AI’s harms. As such there are degrees of AI regulation being pursued in jurisdictions across the globe. Some jurisdictions are taking a more measured approach to artificial intelligence. Others are taking a more active yet still thoughtful approach. However, yet other jurisdictions are crafting AI regulations with overly broad and burdensome provisions. This may hamper the factors necessary for AI’s development and prop up legacy industries, sheltering them from the need to innovate. Hobbling AI could cement incumbents’ positions in the market, hamper new and innovative businesses, and harm global competition.\"\n",
      "CONCISE SUMMARY:\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m Write a concise summary of the following:\n",
      "\"Certain regulatory actions regarding the future of artificial intelligence are of course quite reasonable and necessary as AI has the potential to reshape society in boundless known and unknown manners. The growth of AI will continue to raise questions as it reshapes society; however, any regulation must be tempered with thoughtfulness and a clear understanding of this technology to ensure that markets can facilitate competition and innovation.\"\n",
      "CONCISE SUMMARY:\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 142, but your input_length is only 125. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=62)\n",
      "Your max_length is set to 142, but your input_length is only 73. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=36)\n",
      "Your max_length is set to 142, but your input_length is only 132. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=66)\n",
      "Your max_length is set to 142, but your input_length is only 133. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=66)\n",
      "Your max_length is set to 142, but your input_length is only 97. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=48)\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1265 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m Write a concise summary of the following text delimited by triple backquotes.\n",
      "```Artificial intelligence (AI) is a highly versatile technology. There is a growing regulatory tension between different jurisdictions. Governments need to strengthen their capabilities to understand, leverage, operate, and when it calls for it, regulate this technology. Write a concise summary of the following:\"A Look Into the Global AI Regulatory Landscape\"\n",
      "\n",
      "The Biden-Harris Administration released its long anticipated Executive Order (EO) on AI. In Europe, EU member states recently approved final wording of the AI Act. While the EU sees the potential of AI through its own competitive AI ecosystem, many of the new AI rules remain unclear.\n",
      "\n",
      "\"The White House EO on AI does raise some concerns, but it also represents a positive step forward in AI governance and promises a bright future\" \"The Biden-Harris Administration is acutely aware of this technology and growing regulatory rivalries, and took action on the matter before the newest EO\"\n",
      "\n",
      "The EO on AI has quite a broad scope, directing a number of actions to maximize AI’s potential. Among its many provisions, it proposes new privacy, safety, and security standards. The White House recently announced that “top federal officials working to carry out the AI EO say their agencies have completed all of the 90-day actions asked of them”\n",
      "\n",
      "\"In addition to the federal government, many states are pursuing AI legislation as well\" States are introducing legislation to regulate AI in a number of sectors. Pieces of legislation often fall into one of five key categories: Establishing AI development standards, Labeling various content generated by AI applications, Regulating suggestive algorithmic feeds, and Enhancing oversight of algorithmically-informed decision-making.\n",
      "\n",
      "The focus of these pieces of legislation ranges from protecting children online to ensuring the integrity of our elections. Several states are taking an especially close look at this topic. As most states are only at the beginning of 2024 legislative sessions, the legislative landscape at the state level is likely to continue to evolve.\n",
      "\n",
      "\"To overregulate this sector risks AI evolution stagnating in the United States. AI governance must achieve a balance that ensures the safety and security of citizens while promoting innovation and competition, advancing U.S. AI leadership across the world,\" the report says. The report also calls for the creation of an international body to oversee the development of AI.\n",
      "\n",
      "The European Union’s AI Act aims to create risk-based rules on how AI is developed and used in the EU. Certain practices deemed unacceptable will be entirely prohibited, while AI systems deemed high-risk will be subject to strict requirements. The vote for the Act's formal adoption could occur in March or April.\n",
      "\n",
      "Many of the new AI rules remain unclear and could slow down the development and roll-out of innovative AI applications in Europe. The Act’s proper implementation will therefore be crucial to ensuring that AI rules do not overburden companies in their quest to innovate and compete in a thriving, highly dynamic market.\n",
      "\n",
      "The UK also aspires to hold a positive, leadership role in artificial intelligence. Michelle Donelan, Secretary of State at the Department for Science, Innovation and Technology (DSIT), told a House of Lords Committee that the Government has taken a “pro-innovation” approach to AI.\n",
      "\n",
      "\"The Competition and Markets Authority is being given extensive new powers to intervene in digital markets\" \"There is a risk that premature or overly-broad regulation might inhibit the development of new services with new business models that could benefit consumers\" \"UK copyright law depends on formal changes which are struggling to move forward\"\n",
      "\n",
      "\"More generally, it is still not clear whether the UK’s intention to provide a flexible, pro-innovation approach to AI will survive a slow accretion of restrictions from different regulations and regulators\" \"We need to be proportionate and practical” in addressing risks and “not miss out on opportunities”\n",
      "\n",
      "Bill C-27, the Digital Charter Implementation Act, has been under consideration since June 2022. The bill is split into two parts. The first section overhauls the privacy rules in Canada. The second incorporates the Artificial Intelligence and Data Act, which seeks to establish “common requirements, applicable across Canada.”\n",
      "\n",
      "Artificial intelligence systems are defined with a broad brush. Many of its definitions — such as “high-impact AI systems” or “person responsible” — are left opaque or undefined. interpretations could lead to disclosure of trade secrets, excessive punishments for innovators, and restrictions on services trade.\n",
      "\n",
      "\"Even more concerning, in October 2023, the government stated its intent to include AI used in the “moderation of content that is found on an online communications platform, including a search engine and a social media service” Bill C-27 is still being studied by the House of Commons Standing Committee on Industry and Technology. Once it is voted out of committee, it will require approval from the House and the Senate\"\n",
      "\n",
      "\"The lack of clarity in Bill C-27 and its sweeping application raises concerns that this legislation will introduce an overly burdensome regulatory framework,\" says the committee. Some of the leading innovations in AI warned the Canadian Parliament of these concerns earlier this month. The law could result in the inability to roll out certain services and products in Canada, the committee says.\n",
      "\n",
      "The pressures and potential of AI are pushing many regulators forward in a race to regulate, often due to ill-defined and unproven fears of AI’s harms. As such there are degrees of AI regulation being pursued in jurisdictions across the globe. Some jurisdictions are taking a more measured approach to artificial intelligence. Others are take a more active yet still thoughtful approach.\n",
      "\n",
      "\"Certain regulatory actions regarding the future of artificial intelligence are of course quite reasonable and necessary\" \"AI has the potential to reshape society in boundless known and unknown manners\" \"Any regulation must be tempered with thoughtfulness and a clear understanding of this technology\" \" AI will continue to raise questions as it reshapes society\"```\n",
      "CONCISE SUMMARY:\n",
      "\u001b[0m\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 45\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m news_item\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marticle\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m     44\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSummarizing article: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnews_item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnews_item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlink\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 45\u001b[0m     news_item[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhf_bart_summary\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mhf_bart_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnews_item\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msplit_article\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain\\chains\\base.py:162\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    161\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 162\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    163\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    164\u001b[0m final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[0;32m    165\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[0;32m    166\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain\\chains\\base.py:156\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    149\u001b[0m run_manager \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[0;32m    150\u001b[0m     dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    151\u001b[0m     inputs,\n\u001b[0;32m    152\u001b[0m     name\u001b[38;5;241m=\u001b[39mrun_name,\n\u001b[0;32m    153\u001b[0m )\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 156\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[0;32m    159\u001b[0m     )\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    161\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain\\chains\\combine_documents\\base.py:136\u001b[0m, in \u001b[0;36mBaseCombineDocumentsChain._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;66;03m# Other keys are assumed to be needed for LLM prediction\u001b[39;00m\n\u001b[0;32m    135\u001b[0m other_keys \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_key}\n\u001b[1;32m--> 136\u001b[0m output, extra_return_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcombine_docs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_run_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mother_keys\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    139\u001b[0m extra_return_dict[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_key] \u001b[38;5;241m=\u001b[39m output\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m extra_return_dict\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain\\chains\\combine_documents\\map_reduce.py:236\u001b[0m, in \u001b[0;36mMapReduceDocumentsChain.combine_docs\u001b[1;34m(self, docs, token_max, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    230\u001b[0m question_result_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_chain\u001b[38;5;241m.\u001b[39moutput_key\n\u001b[0;32m    231\u001b[0m result_docs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    232\u001b[0m     Document(page_content\u001b[38;5;241m=\u001b[39mr[question_result_key], metadata\u001b[38;5;241m=\u001b[39mdocs[i]\u001b[38;5;241m.\u001b[39mmetadata)\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;66;03m# This uses metadata from the docs, and the textual results from `results`\u001b[39;00m\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, r \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(map_results)\n\u001b[0;32m    235\u001b[0m ]\n\u001b[1;32m--> 236\u001b[0m result, extra_return_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce_documents_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcombine_docs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresult_docs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_max\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_intermediate_steps:\n\u001b[0;32m    240\u001b[0m     intermediate_steps \u001b[38;5;241m=\u001b[39m [r[question_result_key] \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m map_results]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain\\chains\\combine_documents\\reduce.py:242\u001b[0m, in \u001b[0;36mReduceDocumentsChain.combine_docs\u001b[1;34m(self, docs, token_max, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Combine multiple documents recursively.\u001b[39;00m\n\u001b[0;32m    225\u001b[0m \n\u001b[0;32m    226\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;124;03m    element returned is a dictionary of other keys to return.\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    239\u001b[0m result_docs, extra_return_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_collapse(\n\u001b[0;32m    240\u001b[0m     docs, token_max\u001b[38;5;241m=\u001b[39mtoken_max, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    241\u001b[0m )\n\u001b[1;32m--> 242\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcombine_documents_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcombine_docs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdocs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresult_docs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    244\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain\\chains\\combine_documents\\stuff.py:244\u001b[0m, in \u001b[0;36mStuffDocumentsChain.combine_docs\u001b[1;34m(self, docs, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    242\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_inputs(docs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    243\u001b[0m \u001b[38;5;66;03m# Call predict on the LLM.\u001b[39;00m\n\u001b[1;32m--> 244\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m, {}\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain\\chains\\llm.py:293\u001b[0m, in \u001b[0;36mLLMChain.predict\u001b[1;34m(self, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, callbacks: Callbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m    279\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Format prompt with kwargs and pass to LLM.\u001b[39;00m\n\u001b[0;32m    280\u001b[0m \n\u001b[0;32m    281\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;124;03m            completion = llm.predict(adjective=\"funny\")\u001b[39;00m\n\u001b[0;32m    292\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_key]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain_core\\_api\\deprecation.py:145\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    143\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    144\u001b[0m     emit_warning()\n\u001b[1;32m--> 145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain\\chains\\base.py:363\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \n\u001b[0;32m    333\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[0;32m    355\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    356\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    357\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[0;32m    358\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[0;32m    360\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[0;32m    361\u001b[0m }\n\u001b[1;32m--> 363\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    364\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    365\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    366\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    367\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    368\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain\\chains\\base.py:162\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    161\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 162\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    163\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    164\u001b[0m final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[0;32m    165\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[0;32m    166\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain\\chains\\base.py:156\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    149\u001b[0m run_manager \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[0;32m    150\u001b[0m     dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    151\u001b[0m     inputs,\n\u001b[0;32m    152\u001b[0m     name\u001b[38;5;241m=\u001b[39mrun_name,\n\u001b[0;32m    153\u001b[0m )\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 156\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[0;32m    159\u001b[0m     )\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    161\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain\\chains\\llm.py:103\u001b[0m, in \u001b[0;36mLLMChain._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call\u001b[39m(\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    100\u001b[0m     inputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[0;32m    101\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    102\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m--> 103\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_outputs(response)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain\\chains\\llm.py:115\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[1;34m(self, input_list, run_manager)\u001b[0m\n\u001b[0;32m    113\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m run_manager\u001b[38;5;241m.\u001b[39mget_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm, BaseLanguageModel):\n\u001b[1;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    122\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mbind(stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_kwargs)\u001b[38;5;241m.\u001b[39mbatch(\n\u001b[0;32m    123\u001b[0m         cast(List, prompts), {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks}\n\u001b[0;32m    124\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain_core\\language_models\\llms.py:568\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m    561\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    562\u001b[0m     prompts: List[PromptValue],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    565\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    566\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    567\u001b[0m     prompt_strings \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_string() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m--> 568\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_strings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain_core\\language_models\\llms.py:741\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[1;34m(self, prompts, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    726\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsked to cache, but no cache found at `langchain.cache`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    727\u001b[0m         )\n\u001b[0;32m    728\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    729\u001b[0m         callback_manager\u001b[38;5;241m.\u001b[39mon_llm_start(\n\u001b[0;32m    730\u001b[0m             dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    739\u001b[0m         )\n\u001b[0;32m    740\u001b[0m     ]\n\u001b[1;32m--> 741\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    742\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    743\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[0;32m    745\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain_core\\language_models\\llms.py:605\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[1;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[0;32m    603\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n\u001b[0;32m    604\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[1;32m--> 605\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    606\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m manager, flattened_output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(run_managers, flattened_outputs):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain_core\\language_models\\llms.py:592\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[1;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[0;32m    582\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_generate_helper\u001b[39m(\n\u001b[0;32m    583\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    584\u001b[0m     prompts: List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    588\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    589\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    590\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    591\u001b[0m         output \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 592\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    593\u001b[0m \u001b[43m                \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    594\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    595\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[0;32m    596\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    597\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    598\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    599\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    600\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(prompts, stop\u001b[38;5;241m=\u001b[39mstop)\n\u001b[0;32m    601\u001b[0m         )\n\u001b[0;32m    602\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    603\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain_community\\llms\\huggingface_pipeline.py:203\u001b[0m, in \u001b[0;36mHuggingFacePipeline._generate\u001b[1;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    200\u001b[0m batch_prompts \u001b[38;5;241m=\u001b[39m prompts[i : i \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size]\n\u001b[0;32m    202\u001b[0m \u001b[38;5;66;03m# Process batch of prompts\u001b[39;00m\n\u001b[1;32m--> 203\u001b[0m responses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_prompts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;66;03m# Process each response in the batch\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j, response \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(responses):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\pipelines\\text2text_generation.py:269\u001b[0m, in \u001b[0;36mSummarizationPipeline.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    246\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;124;03m    Summarize the text(s) given as inputs.\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[38;5;124;03m          ids of the summary.\u001b[39;00m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 269\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\pipelines\\text2text_generation.py:167\u001b[0m, in \u001b[0;36mText2TextGenerationPipeline.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    139\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;124;03m    Generate the output text(s) using text(s) given as inputs.\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;124;03m          ids of the generated text.\u001b[39;00m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 167\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    169\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mlist\u001b[39m)\n\u001b[0;32m    170\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(el, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m el \u001b[38;5;129;01min\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m    171\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28mlen\u001b[39m(res) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m result)\n\u001b[0;32m    172\u001b[0m     ):\n\u001b[0;32m    173\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [res[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m result]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\pipelines\\base.py:1143\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[1;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m can_use_iterator:\n\u001b[0;32m   1140\u001b[0m     final_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[0;32m   1141\u001b[0m         inputs, num_workers, batch_size, preprocess_params, forward_params, postprocess_params\n\u001b[0;32m   1142\u001b[0m     )\n\u001b[1;32m-> 1143\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(final_iterator)\n\u001b[0;32m   1144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n\u001b[0;32m   1145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\pipelines\\pt_utils.py:124\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_item()\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterator)\n\u001b[0;32m    125\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(item, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[0;32m    126\u001b[0m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\pipelines\\pt_utils.py:125\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[0;32m    124\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterator)\n\u001b[1;32m--> 125\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;66;03m# Try to infer the size of the batch\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\pipelines\\base.py:1068\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[1;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[0;32m   1066\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[0;32m   1067\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m-> 1068\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1069\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m   1070\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\pipelines\\text2text_generation.py:191\u001b[0m, in \u001b[0;36mText2TextGenerationPipeline._forward\u001b[1;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[0;32m    184\u001b[0m     in_b, input_length \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mshape(model_inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_inputs(\n\u001b[0;32m    187\u001b[0m     input_length,\n\u001b[0;32m    188\u001b[0m     generate_kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin_length\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmin_length),\n\u001b[0;32m    189\u001b[0m     generate_kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_length\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmax_length),\n\u001b[0;32m    190\u001b[0m )\n\u001b[1;32m--> 191\u001b[0m output_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgenerate_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    192\u001b[0m out_b \u001b[38;5;241m=\u001b[39m output_ids\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\generation\\utils.py:1370\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[0;32m   1362\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m   1363\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA decoder-only architecture is being used, but right-padding was detected! For correct \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1364\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration results, please set `padding_side=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m` when initializing the tokenizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1365\u001b[0m         )\n\u001b[0;32m   1367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder_outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m model_kwargs:\n\u001b[0;32m   1368\u001b[0m     \u001b[38;5;66;03m# if model is encoder decoder encoder_outputs are created\u001b[39;00m\n\u001b[0;32m   1369\u001b[0m     \u001b[38;5;66;03m# and added to `model_kwargs`\u001b[39;00m\n\u001b[1;32m-> 1370\u001b[0m     model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_encoder_decoder_kwargs_for_generation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1371\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_input_name\u001b[49m\n\u001b[0;32m   1372\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1374\u001b[0m \u001b[38;5;66;03m# 5. Prepare `input_ids` which will be used for auto-regressive generation\u001b[39;00m\n\u001b[0;32m   1375\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\generation\\utils.py:491\u001b[0m, in \u001b[0;36mGenerationMixin._prepare_encoder_decoder_kwargs_for_generation\u001b[1;34m(self, inputs_tensor, model_kwargs, model_input_name)\u001b[0m\n\u001b[0;32m    489\u001b[0m encoder_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    490\u001b[0m encoder_kwargs[model_input_name] \u001b[38;5;241m=\u001b[39m inputs_tensor\n\u001b[1;32m--> 491\u001b[0m model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder_outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m]: ModelOutput \u001b[38;5;241m=\u001b[39m \u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mencoder_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model_kwargs\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\models\\bart\\modeling_bart.py:1154\u001b[0m, in \u001b[0;36mBartEncoder.forward\u001b[1;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1152\u001b[0m     inputs_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_tokens(input_ids) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_scale\n\u001b[1;32m-> 1154\u001b[0m embed_pos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_positions\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1155\u001b[0m embed_pos \u001b[38;5;241m=\u001b[39m embed_pos\u001b[38;5;241m.\u001b[39mto(inputs_embeds\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m   1157\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m inputs_embeds \u001b[38;5;241m+\u001b[39m embed_pos\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\models\\bart\\modeling_bart.py:135\u001b[0m, in \u001b[0;36mBartLearnedPositionalEmbedding.forward\u001b[1;34m(self, input_ids, past_key_values_length)\u001b[0m\n\u001b[0;32m    130\u001b[0m bsz, seq_len \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m    131\u001b[0m positions \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(\n\u001b[0;32m    132\u001b[0m     past_key_values_length, past_key_values_length \u001b[38;5;241m+\u001b[39m seq_len, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m    133\u001b[0m )\u001b[38;5;241m.\u001b[39mexpand(bsz, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpositions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\sparse.py:162\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\functional.py:2233\u001b[0m, in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2227\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[0;32m   2228\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[0;32m   2229\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m   2230\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[0;32m   2231\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[0;32m   2232\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[1;32m-> 2233\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "\n",
    "bart_summarizer = pipeline(\n",
    "    \"summarization\",\n",
    "    model=\"facebook/bart-large-cnn\",\n",
    "    tokenizer=\"facebook/bart-large-cnn\",\n",
    ")\n",
    "\n",
    "hf_bart_llm = HuggingFacePipeline(pipeline=bart_summarizer, model_kwargs={})\n",
    "\n",
    "\n",
    "map_prompt = \"\"\" Write a concise summary of the following:\n",
    "\"{text}\"\n",
    "CONCISE SUMMARY:\n",
    "\"\"\"\n",
    "map_prompt_template = PromptTemplate(\n",
    "    template=map_prompt,\n",
    "    input_variables=[\"text\"]\n",
    ")\n",
    "\n",
    "combine_prompt = \"\"\" Write a concise summary of the following text delimited by triple backquotes.\n",
    "```{text}```\n",
    "CONCISE SUMMARY:\n",
    "\"\"\"\n",
    "combine_prompt_template = PromptTemplate(\n",
    "    template=combine_prompt,\n",
    "    input_variables=[\"text\"]\n",
    ")\n",
    "\n",
    "\n",
    "hf_bart_chain = load_summarize_chain(\n",
    "    llm=hf_bart_llm,\n",
    "    chain_type=\"map_reduce\",\n",
    "    map_prompt=map_prompt_template,\n",
    "    combine_prompt=combine_prompt_template,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# run chain\n",
    "# for news_item in news_results[\"news\"][:num_results]:\n",
    "for news_item in news_results[\"news\"][2:num_results]:\n",
    "    if news_item.get(\"article\"):\n",
    "        print(\n",
    "            f\"Summarizing article: {news_item['title']} - {news_item['link']}\\n\")\n",
    "        news_item[\"hf_bart_summary\"] = hf_bart_chain.invoke(\n",
    "            news_item[\"split_article\"])\n",
    "        print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='A Look Into the Global AI Regulatory Landscape\\n\\nArtificial intelligence (AI) is a highly versatile technology. From one program’s application in a pastry shop to its later employment in detecting cancer cells, AI is truly integrating itself into many diverse aspects of our world. However, the rapid rise of AI has also intensified the need for governments to strengthen their capabilities to understand, leverage, operate, and when it calls for it, regulate this technology. As a result, there is a growing regulatory tension between different jurisdictions, which includes the development of comprehensive or sector-specific legislation and voluntary guidelines and standards.'),\n",
       " Document(page_content='In June of last year, Josh Landau discussed AI legislation in the U.S. and the effects it could have on the industry. And in late October, the Biden-Harris Administration finally released its long anticipated Executive Order (EO) on AI. In the wake of the NIST Risk Management Framework, as well as the recently released EO and the Blueprint for an AI Bill of Rights, it appears the White House is taking a thoughtful, risk-based approach to regulating AI. While the U.S. is taking a cautiously optimistic stance when it comes to AI, other regimes are moving forward with more broad and burdensome proposals that could very well hinder this burgeoning technology’s development. In Europe, EU member states recently approved final wording of the AI Act. However, while the EU sees the potential of AI through its own competitive AI ecosystem, many of the new AI rules remain unclear and could obstruct the development and roll-out of innovative AI applications across Europe.'),\n",
       " Document(page_content='Moreover, Europe and the U.S. are by no means the only two players in this regulatory rivalry. The UK, Canada, Israel, and many other countries and territories are all pursuing some form of AI regulation.\\n\\nU.S.\\n\\nThe Biden-Harris Administration is acutely aware of this technology and growing regulatory rivalries, and took action on the matter before the newest EO by publishing the Blueprint for an AI Bill of Rights and issuing an EO Advancing Racial Equity and Support for Underserved Communities Through the Federal Government. The White House EO on AI does raise some concerns, but it also represents a positive step forward in AI governance and promises a bright future.'),\n",
       " Document(page_content='\\nThe EO on AI has quite a broad scope, directing a number of actions to maximize AI’s potential. Among its many provisions, it proposes new privacy, safety, and security standards, assigns agencies to develop and share reports and guidelines for the responsible use of AI, and encourages attracting global talent. Commenting on the Biden Administration’s EO on AI, Senators Schumer and Young announced they are also working on legislation that would build upon the Executive Order from the President. Furthermore, the White House recently announced that “top federal officials working to carry out the AI EO say their agencies have completed all of the 90-day actions asked of them.” And most recently, at State of the Net 2024, Congressional AI Caucus Vice Chair Don Beyer said that there is a bipartisan plan from House leaders to create an informal AI task force and pass several AI bills in 2024. These efforts spotlight the fast pace officials are moving to keep pace with the growth of the technology.'),\n",
       " Document(page_content='In addition to the federal government, many states are pursuing AI legislation as well. States are introducing legislation to regulate AI in a number of sectors, with pieces of legislation often falling into one of five key categories:\\n\\nEstablishing AI development standards; Labeling various content generated by AI applications; Regulating suggestive algorithmic feeds Pursuing studies or creating task forces to determine how best to regulate AI; and Enhancing oversight of algorithmically-informed decision-making across broad sectors via comprehensive AI Bills of Rights.'),\n",
       " Document(page_content='\\nThe focus of these pieces of legislation ranges from protecting children online to ensuring the integrity of our elections. Several states are taking an especially close look at this topic. For example, last year Connecticut Senator James Maroney led a multi-state AI task force, which expanded to include lawmakers from state legislatures across the country. Last year, California, which tends to be among the first states to propose regulations on technology, began contemplating legislation such as AB 331, regarding automated decision tools. Now, the California legislature has over ten proposals centered on AI, and Governor Gavin Newsom signed an executive order “to study the development, use, and risks of artificial intelligence (AI) technology throughout the state and to develop a deliberate and responsible process for evaluation and deployment of AI within state government.” As most states are only at the beginning of 2024 legislative sessions, the legislative landscape at the state level is likely to continue to evolve before most sessions adjourn this summer.'),\n",
       " Document(page_content='To overregulate this sector risks AI evolution stagnating in the United States. AI governance must achieve a balance that ensures the safety and security of citizens while promoting innovation and competition, advancing U.S. AI leadership across the world.\\n\\nEU'),\n",
       " Document(page_content='EU\\n\\nBesides the U.S., another regulatory model contributing to the current landscape is the European Union’s AI Act. EU member states recently approved final wording of the AI Act, which was proposed by the European Commission three years ago. The AI Act aims to create risk-based rules on how AI is developed and used in the EU. Certain practices deemed unacceptable will be entirely prohibited, while AI systems deemed high-risk will be subject to strict requirements. The AI Act deviates from its risk-based approach by imposing strict obligations on developers of foundation models, powerful models underpinning all kinds of different applications, including generative AI application. The vote for the Act’s formal adoption could occur in March or April.'),\n",
       " Document(page_content='Boniface de Champris has previously addressed the European AI Act, noting the rules lack clarity and could seriously damage Europe’s economy. Despite improvements to the final text, many of the new AI rules remain unclear and could slow down the development and roll-out of innovative AI applications in Europe. Europe has a highly competitive AI ecosystem; the Act’s proper implementation will therefore be crucial to ensuring that AI rules do not overburden companies in their quest to innovate and compete in a thriving, highly dynamic market.\\n\\nUK'),\n",
       " Document(page_content='UK\\n\\nThe UK also aspires to hold a positive, leadership role in artificial intelligence. Michelle Donelan, Secretary of State at the Department for Science, Innovation and Technology (DSIT), told a House of Lords Committee that the Government has taken a “pro-innovation” approach to AI, addressing risks transparently rather than turning away from AI. She pointed to steps to that end including the AI Opportunities Forum, the AI Safety Summit and international partnerships such as a Memorandum of Understanding with Canada around compute capacity.\\n\\nThe UK does not yet have a landmark AI law. However Donelan and other Ministers point to the Summit and the AI Safety Institute as firsts that show the UK is at the cutting edge in addressing emerging risks. Instead of setting out new legislation, or creating new regulators, the intent is to use existing legislation and existing regulatory bodies to respond to diverse risks as they emerge.'),\n",
       " Document(page_content='However this does not mean there are no challenges in the UK. The Competition and Markets Authority is being given extensive new powers to intervene in digital markets and, if the right checks and balances are not included, there is a risk that premature or overly-broad regulation might inhibit the development of new services with new business models that could benefit consumers. While the UK does have fair dealing, without a more general provision akin to the “fair use” doctrine in the U.S., UK copyright law depends on formal changes which are struggling to move forward.'),\n",
       " Document(page_content='More generally, it is still not clear whether the UK’s intention to provide a flexible, pro-innovation approach to AI will survive a slow accretion of restrictions from different regulations and regulators, or pressure for a larger comprehensive regulatory response. Some parliamentarians are conscious of the risks here. Baroness Stowell, Chairman of the House of Lords Communications and Digital Committee, warned that “we need to be proportionate and practical” in addressing risks and “not miss out on opportunities”. She noted that excessive caution might “exclude smaller players from developing AI services.”\\n\\nCanada'),\n",
       " Document(page_content='Canada\\n\\nIn September, Canada’s Minister of Innovation, Science and Industry, François-Philippe Champagne, voiced an ambition for Canada to be the first country to have AI regulations in place to “inspire the rest of the world.” Although that goal is now unreachable after the EU’s agreement on the AI Act, Canada’s Parliament continues its work to advance what it hopes would be a template for global AI regulation in Bill C-27, the Digital Charter Implementation Act, which itself has been under consideration since June 2022.\\n\\nBill C-27, however, introduces new challenges and concerns. The bill is split into two parts—the first section overhauls the privacy rules in Canada, and the second incorporates the Artificial Intelligence and Data Act, which seeks to establish “common requirements, applicable across Canada, for the design, development and use” of AI systems.'),\n",
       " Document(page_content='Artificial intelligence systems are defined with a broad brush as any technological system that, “autonomously or partly autonomously, processes data related to human activities through the use of a genetic algorithm, a neural network, machine learning or another technique in order to generate content or make decisions, recommendations or predictions.” Many of its definitions — such as “high-impact AI systems” or “person responsible” — are left opaque or undefined, leaving interpretations that could lead to disclosure of trade secrets, excessive punishments for innovators, and restrictions on services trade for online programs.'),\n",
       " Document(page_content='Even more concerning, in October 2023, the government stated its intent to include AI used in the “moderation of content that is found on an online communications platform, including a search engine and a social media service” or the “prioritization of the presentation of such content” under “high-impact” AI systems. This unique inclusion is notable, as it could undermine online services providers’ activity in the Canadian market given the potential broad-sweeping applicability of such a category.\\n\\nBill C-27 is still being studied by the House of Commons Standing Committee on Industry and Technology—once it is voted out of committee, it will require approval from the House of Commons and the Senate (which would need to hold a committee process of its own and could undergo further amendment) before it can receive Royal Assent.'),\n",
       " Document(page_content='The lack of clarity in Bill C-27 and its sweeping application raises concerns that this legislation will introduce an overly burdensome regulatory framework, which would in turn endanger interoperability across the continent for services subject to its obligations. Some of the companies leading innovations in AI warned the Canadian Parliament of these concerns earlier this month, with Meta’s representative telling the Committee that the law could result in the company being unable to roll out certain services and products in Canada. As such, if it remains as is, Bill C-27 could undermine the development of a growing and innovative field by creating regulatory uncertainty and a marketplace hostile to innovative practices.\\n\\nConclusion'),\n",
       " Document(page_content='Conclusion\\n\\nThe pressures and potential of AI are pushing many regulators forward in a race to regulate, often due to ill-defined and unproven fears of AI’s harms. As such there are degrees of AI regulation being pursued in jurisdictions across the globe. Some jurisdictions are taking a more measured approach to artificial intelligence. Others are taking a more active yet still thoughtful approach. However, yet other jurisdictions are crafting AI regulations with overly broad and burdensome provisions. This may hamper the factors necessary for AI’s development and prop up legacy industries, sheltering them from the need to innovate. Hobbling AI could cement incumbents’ positions in the market, hamper new and innovative businesses, and harm global competition.'),\n",
       " Document(page_content='Certain regulatory actions regarding the future of artificial intelligence are of course quite reasonable and necessary as AI has the potential to reshape society in boundless known and unknown manners. The growth of AI will continue to raise questions as it reshapes society; however, any regulation must be tempered with thoughtfulness and a clear understanding of this technology to ensure that markets can facilitate competition and innovation.')]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_results[\"news\"][2][\"split_article\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# news_results[\"news\"][2][\"split_article\"]\n",
    "\n",
    "for i in news_results[\"news\"][2][\"split_article\"]:\n",
    "    print(i)\n",
    "    print(hf_bart_chain.invoke([i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Title: The global economy in 2024: World Bank predicts slowest half-decade of growth in 30 years - People & Profit\n",
      "Link: https://www.france24.com/en/tv-shows/people-profit/20240216-the-global-economy-in-2024-world-bank-predicts-slowest-half-decade-of-growth-in-30-years\n",
      "\n",
      "oai_summary: \u001b[32m  The World Bank predicts slow economic growth for the next five years, which could hinder development and climate goals. Developing and low-income economies will be most affected. The World Bank's Deputy Chief Economist talks about these findings in an interview with FRANCE 24.\u001b[0m\n",
      "\n",
      "hf_hub_summary: \u001b[32mThe World Bank has warned that the global economy is set to grow at a rate of just 2% per year for the next five years, a far cry from the 4% growth it predicted in its Global Economic Prospects report.\u001b[0m\n",
      "\n",
      "hf_bart_summary: \u001b[32mWorld Bank predicts slowest half-decade of growth in 30 years. This is having devastating consequences, especially in developing and low-income economies. For more, FRANCE 24's Charles Pellegrin speaks to the World Bank's Deputy Chief Economist Ayhan Kose.\u001b[0m\n",
      "\n",
      "Title: The Coming Drag on Economic Growth From Security Competition in Asia and Europe\n",
      "Link: https://worldview.stratfor.com/article/coming-drag-economic-growth-security-competition-asia-and-europe\n",
      "\n",
      "oai_summary: \u001b[32m \n",
      "\n",
      "Competition for security in Asia and Europe will lead to higher national defense spending in the next decade, though it will still be lower than during the Cold War. Trump's remarks have sparked a discussion on military spending, but it continues to rise in Europe and other regions. Global military spending decreased after the Cold War, except for the US due to conflicts in Afghanistan and Iraq. It is projected to remain stable in 2022.\u001b[0m\n",
      "\n",
      "hf_hub_summary: \u001b[32mThe Global Economic Prospects report, released by the World Economic Forum, projects that global defense spending will increase by a third over the next decade, driven by rising security competition in Asia and Europe.\u001b[0m\n",
      "\n",
      "hf_bart_summary: \u001b[32mDefense spending measured as a share of GDP will remain below levels seen during the Cold War. Military spending is nevertheless on the rise in Europe and elsewhere. Write a concise summary of the following: \"Defense spending is still below levels reached in the 1980s and 1990s\"\u001b[0m\n",
      "\n",
      "Title: Russia's Invasion of Ukraine Threatens Indonesia's Economy\n",
      "Link: https://www.businessinsider.com/sc/russias-invasion-of-ukraine-threatens-indonesias-economy\n",
      "\n",
      "oai_summary: \u001b[32m  Indonesia has maintained economic stability and growth despite external risks from the war in Ukraine. The country aims to become a top player in the global Islamic economy and a developed nation by 2045, but this may be impacted by rising global interest rates and external debt financing. Indonesia has applied to join the OECD and maintains a \"free and active\" foreign policy, but the Ukraine war and global instability may pose challenges to its goals.\u001b[0m\n",
      "\n",
      "hf_hub_summary: \u001b[32mIndonesia's support for a just and lasting peace for Ukraine is a crucial part of the country's plans to become a global player with greater weight.\u001b[0m\n",
      "\n",
      "hf_bart_summary: \u001b[32mIndonesia has weathered the geopolitical storms of 2022/3 pretty well, according to the World Bank. The country could be ranked as the world's fourth-biggest economy by 2050. But global stability continues to be threatened by Russia's invasion of Ukraine, that remains a distant dream.\u001b[0m\n",
      "\n",
      "Title: Recession has struck some of the world's top economies. The US keeps defying expectations\n",
      "Link: https://abcnews.go.com/US/wireStory/recession-struck-worlds-top-economies-us-defying-expectations-107272969\n",
      "\n",
      "oai_summary: \u001b[32m  \n",
      "Japan and UK economies weakened, possibly entering recession in Q4 of 2023. US continues to experience growth due to consumer spending and government stimulus, with a strong stock market and positive global outlook. US sheltered from recession by pandemic aid, government spending, and immigration. Other countries facing economic challenges. Inflation a top concern for US consumers, particularly low-income individuals.\n",
      "\u001b[0m\n",
      "\n",
      "hf_hub_summary: \u001b[32mConsumers in the United States have benefited from a long-term, low-interest-rate environment that has allowed them to borrow and spend more.\u001b[0m\n",
      "\n",
      "hf_bart_summary: \u001b[32mJapan and the United Kingdom said their economies likely weakened during the final three months of 2023. Yet in the United States, the economy motored ahead in last year’s fourth quarter. The mood on Wall Street is so positive that the main measure of the U.S. stock market topped the 5,000 level last week for the first time.\u001b[0m\n",
      "\n",
      "Title: Japan slips into a recession and loses its spot as the world's third-largest economy\n",
      "Link: https://apnews.com/article/japan-economy-2023-gdp-893d53deba654c4924e4924f0b321cc5\n",
      "\n",
      "oai_summary: \u001b[32m \n",
      "Japan's economy has dropped to the fourth-largest in the world, falling behind Germany due to a 0.4% contraction in the last quarter of 2023. This is attributed to a declining population and productivity, leading to a shrinking gap between developed and emerging nations. India is expected to overtake Japan in GDP. Factors such as a labor shortage, slow growth, stagnant wages, and limited foreign labor and investment also contribute to Japan's economic struggles.\u001b[0m\n",
      "\n",
      "hf_hub_summary: \u001b[32mJapan’s economy is now the world’s fourth-largest after it contracted in the last quarter of 2023 and fell behind Germany. The Belgian economy grew at a slower pace in the first quarter than expected, according to a survey released on Tuesday.\u001b[0m\n",
      "\n",
      "hf_bart_summary: \u001b[32mJapan's economy shrank at an annual rate of 0.4% in October to December. Japan’s economy was the second largest until 2010, when it was overtaken by China's. A weaker Japanese yen was a key factor in the drop to fourth place.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Print the summaries\n",
    "for i in news_results[\"news\"][:num_results]:\n",
    "    if i.get(\"article\"):\n",
    "        print(f\"\\nTitle: {i['title']}\\nLink: {i['link']}\")\n",
    "        print(\n",
    "            f\"\\noai_summary: \\033[32m {i['oai_summary']['output_text']}\\033[0m\")\n",
    "        print(\n",
    "            f\"\\nhf_hub_summary: \\033[32m{i['hf_hub_summary']['output_text']}\\033[0m\")\n",
    "        print(\n",
    "            f\"\\nhf_bart_summary: \\033[32m{i['hf_bart_summary']['output_text']}\\033[0m\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarization with Huggingface Open Source Smaller Local Models with LangChain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing article: The global economy in 2024: World Bank predicts slowest half-decade of growth in 30 years - People & Profit - https://www.france24.com/en/tv-shows/people-profit/20240216-the-global-economy-in-2024-world-bank-predicts-slowest-half-decade-of-growth-in-30-years\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 142, but your input_length is only 77. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=38)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing article: The Coming Drag on Economic Growth From Security Competition in Asia and Europe - https://worldview.stratfor.com/article/coming-drag-economic-growth-security-competition-asia-and-europe\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 142, but your input_length is only 97. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=48)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing article: Russia's Invasion of Ukraine Threatens Indonesia's Economy - https://www.businessinsider.com/sc/russias-invasion-of-ukraine-threatens-indonesias-economy\n",
      "\n",
      "Summarizing article: Recession has struck some of the world's top economies. The US keeps defying expectations - https://abcnews.go.com/US/wireStory/recession-struck-worlds-top-economies-us-defying-expectations-107272969\n",
      "\n",
      "Summarizing article: Japan slips into a recession and loses its spot as the world's third-largest economy - https://apnews.com/article/japan-economy-2023-gdp-893d53deba654c4924e4924f0b321cc5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 142, but your input_length is only 121. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=60)\n"
     ]
    }
   ],
   "source": [
    "hf_distilbart_summarizer = pipeline(\n",
    "    \"summarization\", model=\"sshleifer/distilbart-cnn-12-6\"\n",
    ")\n",
    "\n",
    "hf_distilbart_llm = HuggingFacePipeline(\n",
    "    pipeline=hf_distilbart_summarizer, model_kwargs={}\n",
    ")\n",
    "\n",
    "\n",
    "hf_distilbart_chain = load_summarize_chain(\n",
    "    llm=hf_distilbart_llm,\n",
    "    chain_type=\"map_reduce\",\n",
    "    # verbose=True\n",
    ")\n",
    "\n",
    "# run chain\n",
    "for news_item in news_results[\"news\"][:num_results]:\n",
    "    if news_item.get(\"article\"):\n",
    "        print(\n",
    "            f\"Summarizing article: {news_item['title']} - {news_item['link']}\\n\")\n",
    "        news_item[\"hf_distilbart_summary\"] = hf_distilbart_chain.invoke(\n",
    "            news_item[\"split_article\"]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Title: The global economy in 2024: World Bank predicts slowest half-decade of growth in 30 years - People & Profit\n",
      "Link: https://www.france24.com/en/tv-shows/people-profit/20240216-the-global-economy-in-2024-world-bank-predicts-slowest-half-decade-of-growth-in-30-years\n",
      "oai_summary: \u001b[32m  The World Bank predicts slow economic growth for the next five years, which could hinder development and climate goals. Developing and low-income economies will be most affected. The World Bank's Deputy Chief Economist talks about these findings in an interview with FRANCE 24.\u001b[0m\n",
      "hf_hub_summary: \u001b[32mThe World Bank has warned that the global economy is set to grow at a rate of just 2% per year for the next five years, a far cry from the 4% growth it predicted in its Global Economic Prospects report.\u001b[0m\n",
      "hf_bart_summary: \u001b[32mWorld Bank predicts slowest half-decade of growth in 30 years. This is having devastating consequences, especially in developing and low-income economies. For more, FRANCE 24's Charles Pellegrin speaks to the World Bank's Deputy Chief Economist Ayhan Kose.\u001b[0m\n",
      "hf_distilbart_summary: \u001b[32m World Bank predicts slowest half-decade of growth in 30 years . This is having devastating consequences, especially in developing and low-income economies . For more, FRANCE 24's Charles Pellegrin speaks to the World Bank's Deputy Chief Economist Ayhan Kose .\u001b[0m\n",
      "\n",
      "Title: The Coming Drag on Economic Growth From Security Competition in Asia and Europe\n",
      "Link: https://worldview.stratfor.com/article/coming-drag-economic-growth-security-competition-asia-and-europe\n",
      "oai_summary: \u001b[32m \n",
      "\n",
      "Competition for security in Asia and Europe will lead to higher national defense spending in the next decade, though it will still be lower than during the Cold War. Trump's remarks have sparked a discussion on military spending, but it continues to rise in Europe and other regions. Global military spending decreased after the Cold War, except for the US due to conflicts in Afghanistan and Iraq. It is projected to remain stable in 2022.\u001b[0m\n",
      "hf_hub_summary: \u001b[32mThe Global Economic Prospects report, released by the World Economic Forum, projects that global defense spending will increase by a third over the next decade, driven by rising security competition in Asia and Europe.\u001b[0m\n",
      "hf_bart_summary: \u001b[32mDefense spending measured as a share of GDP will remain below levels seen during the Cold War. Military spending is nevertheless on the rise in Europe and elsewhere. Write a concise summary of the following: \"Defense spending is still below levels reached in the 1980s and 1990s\"\u001b[0m\n",
      "hf_distilbart_summary: \u001b[32m Defense spending measured as a share of GDP will remain below levels seen during the Cold War . Recent remarks by former U.S. President Donald Trump about the need for European NATO member states to increase military spending have reignited a debate . The United States proved a notable exception among the world's largest economies against the backdrop of Washington's wars in Afghanistan and Iraq .\u001b[0m\n",
      "\n",
      "Title: Russia's Invasion of Ukraine Threatens Indonesia's Economy\n",
      "Link: https://www.businessinsider.com/sc/russias-invasion-of-ukraine-threatens-indonesias-economy\n",
      "oai_summary: \u001b[32m  Indonesia has maintained economic stability and growth despite external risks from the war in Ukraine. The country aims to become a top player in the global Islamic economy and a developed nation by 2045, but this may be impacted by rising global interest rates and external debt financing. Indonesia has applied to join the OECD and maintains a \"free and active\" foreign policy, but the Ukraine war and global instability may pose challenges to its goals.\u001b[0m\n",
      "hf_hub_summary: \u001b[32mIndonesia's support for a just and lasting peace for Ukraine is a crucial part of the country's plans to become a global player with greater weight.\u001b[0m\n",
      "hf_bart_summary: \u001b[32mIndonesia has weathered the geopolitical storms of 2022/3 pretty well, according to the World Bank. The country could be ranked as the world's fourth-biggest economy by 2050. But global stability continues to be threatened by Russia's invasion of Ukraine, that remains a distant dream.\u001b[0m\n",
      "hf_distilbart_summary: \u001b[32m Indonesia is aiming for top spot in the State of the Global Islamic Economy index, after hitting third place in December 2023 . By 2027, it's on track to replace Russia as the world's sixth-largest economy (by PPP) And by 2045, the country seeks developed-nation status . The World Bank predicts that Indonesian GDP growth will slow to an average of 4.9% over 2024-26 .\u001b[0m\n",
      "\n",
      "Title: Recession has struck some of the world's top economies. The US keeps defying expectations\n",
      "Link: https://abcnews.go.com/US/wireStory/recession-struck-worlds-top-economies-us-defying-expectations-107272969\n",
      "oai_summary: \u001b[32m  \n",
      "Japan and UK economies weakened, possibly entering recession in Q4 of 2023. US continues to experience growth due to consumer spending and government stimulus, with a strong stock market and positive global outlook. US sheltered from recession by pandemic aid, government spending, and immigration. Other countries facing economic challenges. Inflation a top concern for US consumers, particularly low-income individuals.\n",
      "\u001b[0m\n",
      "hf_hub_summary: \u001b[32mConsumers in the United States have benefited from a long-term, low-interest-rate environment that has allowed them to borrow and spend more.\u001b[0m\n",
      "hf_bart_summary: \u001b[32mJapan and the United Kingdom said their economies likely weakened during the final three months of 2023. Yet in the United States, the economy motored ahead in last year’s fourth quarter. The mood on Wall Street is so positive that the main measure of the U.S. stock market topped the 5,000 level last week for the first time.\u001b[0m\n",
      "hf_distilbart_summary: \u001b[32m Japan and the United Kingdom say their economies likely weakened during the final three months of 2023 . Yet in the United States, the economy motored ahead in last year’s fourth quarter for a sixth straight quarter of growth . The International Monetary Fund cites greater-than-expected resilience in the U.S. economy as a major reason .\u001b[0m\n",
      "\n",
      "Title: Japan slips into a recession and loses its spot as the world's third-largest economy\n",
      "Link: https://apnews.com/article/japan-economy-2023-gdp-893d53deba654c4924e4924f0b321cc5\n",
      "oai_summary: \u001b[32m \n",
      "Japan's economy has dropped to the fourth-largest in the world, falling behind Germany due to a 0.4% contraction in the last quarter of 2023. This is attributed to a declining population and productivity, leading to a shrinking gap between developed and emerging nations. India is expected to overtake Japan in GDP. Factors such as a labor shortage, slow growth, stagnant wages, and limited foreign labor and investment also contribute to Japan's economic struggles.\u001b[0m\n",
      "hf_hub_summary: \u001b[32mJapan’s economy is now the world’s fourth-largest after it contracted in the last quarter of 2023 and fell behind Germany. The Belgian economy grew at a slower pace in the first quarter than expected, according to a survey released on Tuesday.\u001b[0m\n",
      "hf_bart_summary: \u001b[32mJapan's economy shrank at an annual rate of 0.4% in October to December. Japan’s economy was the second largest until 2010, when it was overtaken by China's. A weaker Japanese yen was a key factor in the drop to fourth place.\u001b[0m\n",
      "hf_distilbart_summary: \u001b[32m Japan's economy shrank at an annual rate of 0.4% in October to December, according to Cabinet Office data . Japan’s economy was the second largest until 2010, when it was overtaken by China's . A weaker Japanese yen was a key factor in the drop to fourth place . Consumption fell for three straight quarters last year .\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Print the summaries\n",
    "for i in news_results[\"news\"][:num_results]:\n",
    "    if i.get(\"article\"):\n",
    "        print(f\"\\nTitle: {i['title']}\\nLink: {i['link']}\")\n",
    "        print(\n",
    "            f\"oai_summary: \\033[32m {i['oai_summary']['output_text']}\\033[0m\")\n",
    "        print(\n",
    "            f\"hf_hub_summary: \\033[32m{i['hf_hub_summary']['output_text']}\\033[0m\")\n",
    "        print(\n",
    "            f\"hf_bart_summary: \\033[32m{i['hf_bart_summary']['output_text']}\\033[0m\")\n",
    "        print(\n",
    "            f\"hf_distilbart_summary: \\033[32m{i['hf_distilbart_summary']['output_text']}\\033[0m\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarization with Huggingface Open Source Smaller Local Models with LangChain - Falconsai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_falconsai_summarizer = pipeline(\n",
    "    \"summarization\", model=\"Falconsai/text_summarization\"\n",
    ")\n",
    "\n",
    "hf_falconsai_llm = HuggingFacePipeline(\n",
    "    pipeline=hf_falconsai_summarizer, model_kwargs={}\n",
    ")\n",
    "\n",
    "\n",
    "hf_falconsai_chain = load_summarize_chain(\n",
    "    llm=hf_falconsai_llm,\n",
    "    chain_type=\"map_reduce\",\n",
    "    # verbose=True\n",
    ")\n",
    "\n",
    "# run chain\n",
    "for news_item in news_results[\"news\"][:num_results]:\n",
    "    if news_item.get(\"article\"):\n",
    "        print(\n",
    "            f\"Summarizing article: {news_item['title']} - {news_item['link']}\\n\")\n",
    "        news_item[\"hf_falconsai_summary\"] = hf_falconsai_chain.invoke(\n",
    "            news_item[\"split_article\"]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Title: The global economy in 2024: World Bank predicts slowest half-decade of growth in 30 years - People & Profit\n",
      "Link: https://www.france24.com/en/tv-shows/people-profit/20240216-the-global-economy-in-2024-world-bank-predicts-slowest-half-decade-of-growth-in-30-years\n",
      "oai_summary: \u001b[32m  The World Bank predicts slow economic growth for the next five years, which could hinder development and climate goals. Developing and low-income economies will be most affected. The World Bank's Deputy Chief Economist talks about these findings in an interview with FRANCE 24.\u001b[0m\n",
      "hf_hub_summary: \u001b[32mThe World Bank has warned that the global economy is set to grow at a rate of just 2% per year for the next five years, a far cry from the 4% growth it predicted in its Global Economic Prospects report.\u001b[0m\n",
      "hf_bart_summary: \u001b[32mWorld Bank predicts slowest half-decade of growth in 30 years. This is having devastating consequences, especially in developing and low-income economies. For more, FRANCE 24's Charles Pellegrin speaks to the World Bank's Deputy Chief Economist Ayhan Kose.\u001b[0m\n",
      "hf_distilbart_summary: \u001b[32m World Bank predicts slowest half-decade of growth in 30 years . This is having devastating consequences, especially in developing and low-income economies . For more, FRANCE 24's Charles Pellegrin speaks to the World Bank's Deputy Chief Economist Ayhan Kose .\u001b[0m\n",
      "hf_falconsai_summary: \u001b[32mThe global economy predicts slowest half-decade of growth in 30 years 13:16 PEOPLE & PROFIT FRANCE 24 Play . This is having devastating consequences, especially in developing and low-income economies .\u001b[0m\n",
      "\n",
      "Title: The Coming Drag on Economic Growth From Security Competition in Asia and Europe\n",
      "Link: https://worldview.stratfor.com/article/coming-drag-economic-growth-security-competition-asia-and-europe\n",
      "oai_summary: \u001b[32m \n",
      "\n",
      "Competition for security in Asia and Europe will lead to higher national defense spending in the next decade, though it will still be lower than during the Cold War. Trump's remarks have sparked a discussion on military spending, but it continues to rise in Europe and other regions. Global military spending decreased after the Cold War, except for the US due to conflicts in Afghanistan and Iraq. It is projected to remain stable in 2022.\u001b[0m\n",
      "hf_hub_summary: \u001b[32mThe Global Economic Prospects report, released by the World Economic Forum, projects that global defense spending will increase by a third over the next decade, driven by rising security competition in Asia and Europe.\u001b[0m\n",
      "hf_bart_summary: \u001b[32mDefense spending measured as a share of GDP will remain below levels seen during the Cold War. Military spending is nevertheless on the rise in Europe and elsewhere. Write a concise summary of the following: \"Defense spending is still below levels reached in the 1980s and 1990s\"\u001b[0m\n",
      "hf_distilbart_summary: \u001b[32m Defense spending measured as a share of GDP will remain below levels seen during the Cold War . Recent remarks by former U.S. President Donald Trump about the need for European NATO member states to increase military spending have reignited a debate . The United States proved a notable exception among the world's largest economies against the backdrop of Washington's wars in Afghanistan and Iraq .\u001b[0m\n",
      "hf_falconsai_summary: \u001b[32m\"Increasing security competition in Asia and Europe will lead to a significant acceleration of national defense spending\" defense spending measured as a share of GDP will remain below levels seen during the Cold War .\u001b[0m\n",
      "\n",
      "Title: Russia's Invasion of Ukraine Threatens Indonesia's Economy\n",
      "Link: https://www.businessinsider.com/sc/russias-invasion-of-ukraine-threatens-indonesias-economy\n",
      "oai_summary: \u001b[32m  Indonesia has maintained economic stability and growth despite external risks from the war in Ukraine. The country aims to become a top player in the global Islamic economy and a developed nation by 2045, but this may be impacted by rising global interest rates and external debt financing. Indonesia has applied to join the OECD and maintains a \"free and active\" foreign policy, but the Ukraine war and global instability may pose challenges to its goals.\u001b[0m\n",
      "hf_hub_summary: \u001b[32mIndonesia's support for a just and lasting peace for Ukraine is a crucial part of the country's plans to become a global player with greater weight.\u001b[0m\n",
      "hf_bart_summary: \u001b[32mIndonesia has weathered the geopolitical storms of 2022/3 pretty well, according to the World Bank. The country could be ranked as the world's fourth-biggest economy by 2050. But global stability continues to be threatened by Russia's invasion of Ukraine, that remains a distant dream.\u001b[0m\n",
      "hf_distilbart_summary: \u001b[32m Indonesia is aiming for top spot in the State of the Global Islamic Economy index, after hitting third place in December 2023 . By 2027, it's on track to replace Russia as the world's sixth-largest economy (by PPP) And by 2045, the country seeks developed-nation status . The World Bank predicts that Indonesian GDP growth will slow to an average of 4.9% over 2024-26 .\u001b[0m\n",
      "hf_falconsai_summary: \u001b[32mIndonesia has weathered the geopolitical storms of 2022/3 pretty well . But external risks, including Russia's war on Ukraine, continue to cloud the horizon . By 2027, Indonesia is on track to replace Russia as the world's sixth-largest economy .\u001b[0m\n",
      "\n",
      "Title: Recession has struck some of the world's top economies. The US keeps defying expectations\n",
      "Link: https://abcnews.go.com/US/wireStory/recession-struck-worlds-top-economies-us-defying-expectations-107272969\n",
      "oai_summary: \u001b[32m  \n",
      "Japan and UK economies weakened, possibly entering recession in Q4 of 2023. US continues to experience growth due to consumer spending and government stimulus, with a strong stock market and positive global outlook. US sheltered from recession by pandemic aid, government spending, and immigration. Other countries facing economic challenges. Inflation a top concern for US consumers, particularly low-income individuals.\n",
      "\u001b[0m\n",
      "hf_hub_summary: \u001b[32mConsumers in the United States have benefited from a long-term, low-interest-rate environment that has allowed them to borrow and spend more.\u001b[0m\n",
      "hf_bart_summary: \u001b[32mJapan and the United Kingdom said their economies likely weakened during the final three months of 2023. Yet in the United States, the economy motored ahead in last year’s fourth quarter. The mood on Wall Street is so positive that the main measure of the U.S. stock market topped the 5,000 level last week for the first time.\u001b[0m\n",
      "hf_distilbart_summary: \u001b[32m Japan and the United Kingdom say their economies likely weakened during the final three months of 2023 . Yet in the United States, the economy motored ahead in last year’s fourth quarter for a sixth straight quarter of growth . The International Monetary Fund cites greater-than-expected resilience in the U.S. economy as a major reason .\u001b[0m\n",
      "hf_falconsai_summary: \u001b[32m\"Both Japan and the United Kingdom said their economies likely weakened during the final three months of 2023 . For each, it would be the second straight quarter that’s happened . Yet in the United States, the economy motored ahead in last year’s fourth quarter for a sixth straight quarter of growth .\u001b[0m\n",
      "\n",
      "Title: Japan slips into a recession and loses its spot as the world's third-largest economy\n",
      "Link: https://apnews.com/article/japan-economy-2023-gdp-893d53deba654c4924e4924f0b321cc5\n",
      "oai_summary: \u001b[32m \n",
      "Japan's economy has dropped to the fourth-largest in the world, falling behind Germany due to a 0.4% contraction in the last quarter of 2023. This is attributed to a declining population and productivity, leading to a shrinking gap between developed and emerging nations. India is expected to overtake Japan in GDP. Factors such as a labor shortage, slow growth, stagnant wages, and limited foreign labor and investment also contribute to Japan's economic struggles.\u001b[0m\n",
      "hf_hub_summary: \u001b[32mJapan’s economy is now the world’s fourth-largest after it contracted in the last quarter of 2023 and fell behind Germany. The Belgian economy grew at a slower pace in the first quarter than expected, according to a survey released on Tuesday.\u001b[0m\n",
      "hf_bart_summary: \u001b[32mJapan's economy shrank at an annual rate of 0.4% in October to December. Japan’s economy was the second largest until 2010, when it was overtaken by China's. A weaker Japanese yen was a key factor in the drop to fourth place.\u001b[0m\n",
      "hf_distilbart_summary: \u001b[32m Japan's economy shrank at an annual rate of 0.4% in October to December, according to Cabinet Office data . Japan’s economy was the second largest until 2010, when it was overtaken by China's . A weaker Japanese yen was a key factor in the drop to fourth place . Consumption fell for three straight quarters last year .\u001b[0m\n",
      "hf_falconsai_summary: \u001b[32mWrite a concise summary of the following: \"Japan’s nominal GDP totaled $4.2 trillion last year . Germany’s was $4.4 trillion, or $4.5 trillion, depending on currency conversion . Japan's relative weakness also reflects a decline in its population and lagging competitiveness .\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Print the summaries\n",
    "for i in news_results[\"news\"][:num_results]:\n",
    "    if i.get(\"article\"):\n",
    "        print(f\"\\nTitle: {i['title']}\\nLink: {i['link']}\")\n",
    "        print(\n",
    "            f\"oai_summary: \\033[32m {i['oai_summary']['output_text']}\\033[0m\")\n",
    "        print(\n",
    "            f\"hf_hub_summary: \\033[32m{i['hf_hub_summary']['output_text']}\\033[0m\")\n",
    "        print(\n",
    "            f\"hf_bart_summary: \\033[32m{i['hf_bart_summary']['output_text']}\\033[0m\")\n",
    "        print(\n",
    "            f\"hf_distilbart_summary: \\033[32m{i['hf_distilbart_summary']['output_text']}\\033[0m\"\n",
    "        )\n",
    "        print(\n",
    "            f\"hf_falconsai_summary: \\033[32m{i['hf_falconsai_summary']['output_text']}\\033[0m\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarization with Huggingface Open Source Smaller Local Models with LangChain - MistralAI Hosted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for HuggingFaceHub\n__root__\n  Did not find huggingfacehub_api_token, please add an environment variable `HUGGINGFACEHUB_API_TOKEN` which contains it, or pass `huggingfacehub_api_token` as a named parameter. (type=value_error)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchains\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msummarize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_summarize_chain\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhuggingface_hub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HuggingFaceHub\n\u001b[1;32m----> 4\u001b[0m hf_hub_llm \u001b[38;5;241m=\u001b[39m \u001b[43mHuggingFaceHub\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmistralai/Mixtral-8x7B-Instruct-v0.1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_length\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m hf_hub_chain \u001b[38;5;241m=\u001b[39m load_summarize_chain(\n\u001b[0;32m     10\u001b[0m     llm\u001b[38;5;241m=\u001b[39mhf_hub_llm,\n\u001b[0;32m     11\u001b[0m     chain_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmap_reduce\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m# verbose=True\u001b[39;00m\n\u001b[0;32m     13\u001b[0m )\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# run chain\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# for news_item in news_results[\"news\"][:num_results]:\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain_core\\load\\serializable.py:107\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 107\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lc_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pydantic\\v1\\main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[1;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[0;32m    339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m validate_model(__pydantic_self__\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, data)\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[1;32m--> 341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    343\u001b[0m     object_setattr(__pydantic_self__, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__dict__\u001b[39m\u001b[38;5;124m'\u001b[39m, values)\n",
      "\u001b[1;31mValidationError\u001b[0m: 1 validation error for HuggingFaceHub\n__root__\n  Did not find huggingfacehub_api_token, please add an environment variable `HUGGINGFACEHUB_API_TOKEN` which contains it, or pass `huggingfacehub_api_token` as a named parameter. (type=value_error)"
     ]
    }
   ],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.llms.huggingface_hub import HuggingFaceHub\n",
    "\n",
    "hf_hub_llm = HuggingFaceHub(\n",
    "    repo_id=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
    "    model_kwargs={\"temperature\": 0.3, \"max_length\": 512},\n",
    ")\n",
    "\n",
    "hf_hub_chain = load_summarize_chain(\n",
    "    llm=hf_hub_llm,\n",
    "    chain_type=\"map_reduce\",\n",
    "    # verbose=True\n",
    ")\n",
    "\n",
    "# run chain\n",
    "# for news_item in news_results[\"news\"][:num_results]:\n",
    "for news_item in news_results[\"news\"][1:num_results]:\n",
    "    if news_item.get(\"article\"):\n",
    "        print(\n",
    "            f\"Summarizing article: {news_item['title']} - {news_item['link']}\\n\")\n",
    "        news_item[\"hf_hub_summary\"] = hf_hub_chain.invoke(\n",
    "            news_item[\"split_article\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "import torch\n",
    "from transformers import BitsAndBytesConfig\n",
    "from langchain import HuggingFacePipeline\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "model_id = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "\n",
    "model_4bit = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    quantization_config=quantization_config,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_4bit,\n",
    "    tokenizer=tokenizer,\n",
    "    use_cache=True,\n",
    "    device_map=\"auto\",\n",
    "    max_length=500,\n",
    "    do_sample=True,\n",
    "    top_k=5,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the summaries\n",
    "for i in news_results[\"news\"][:num_results]:\n",
    "    if i.get(\"article\"):\n",
    "        print(f\"\\nTitle: {i['title']}\\nLink: {i['link']}\")\n",
    "        print(\n",
    "            f\"oai_summary: \\033[32m {i['oai_summary']['output_text']}\\033[0m\")\n",
    "        print(\n",
    "            f\"hf_hub_summary: \\033[32m{i['hf_hub_summary']['output_text']}\\033[0m\")\n",
    "        print(\n",
    "            f\"hf_bart_summary: \\033[32m{i['hf_bart_summary']['output_text']}\\033[0m\")\n",
    "        print(\n",
    "            f\"hf_distilbart_summary: \\033[32m{i['hf_distilbart_summary']['output_text']}\\033[0m\"\n",
    "        )\n",
    "        print(\n",
    "            f\"hf_falconsai_summary: \\033[32m{i['hf_falconsai_summary']['output_text']}\\033[0m\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Reading\n",
    "\n",
    "1. [LLM Bootcamp](https://github.com/miztiik/llm-bootcamp)\n",
    "1. [Revolutionizing News Summarization](https://www.width.ai/post/revolutionizing-news-summarization-exploring-the-power-of-gpt-in-zero-shot-and-specialized-tasks)\n",
    "1. [Summarizer For Any Size Document](https://www.width.ai/post/gpt3-summarizer)\n",
    "1. [Langchain Summarization 1. Stuff & Map Reduce](https://python.langchain.com/docs/use_cases/summarization)\n",
    "1. [Langchain Google Serper](https://python.langchain.com/docs/integrations/tools/google_serper)\n",
    "1. [Hugging Face Local Pipelines](https://python.langchain.com/docs/integrations/llms/huggingface_pipelines)\n",
    "1. [Chunking Strategies for LLM Applications](https://www.pinecone.io/learn/chunking-strategies/)\n",
    "1. [Optimal Chunk-Size for Large Document Summarization](https://vectify.ai/blog/LargeDocumentSummarization)\n",
    "1 .[4 Powerful Long Text Summarization Methods With Real Examples](https://www.width.ai/post/4-long-text-summarization-methods)\n",
    "\n",
    "1. [5 Levels Of Summarization: Novice to Expert](https://www.youtube.com/watch?v=qaPMdcCqtWk)\n",
    "1. [Generating Summaries for Large Documents with Llama2 using Hugging Face and Langchain](https://medium.com/@ankit941208/generating-summaries-for-large-documents-with-llama2-using-hugging-face-and-langchain-f7de567339d2)\n",
    "1. [Py-LangChain-PDF-Summary](https://github.com/dmitrimahayana/Py-LangChain-PDF-Summary/blob/master/02_RAG_GPT4ALL.py)\n",
    "1. [Langchain Text Summarization with OpenAI](https://github.com/krishnaik06/Complete-Langchain-Tutorials/blob/main/Text%20summarization/summarization.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"Write a concise summary of the following:\n",
    "\n",
    "\n",
    "{text}\n",
    "\n",
    "\n",
    "CONCISE SUMMARY:\"\"\"\n",
    "PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"text\"])\n",
    "refine_template = (\n",
    "    \"Your job is to produce a final summary\\n\"\n",
    "    \"We have provided an existing summary up to a certain point: {existing_answer}\\n\"\n",
    "    \"We have the opportunity to refine the existing summary\"\n",
    "    \"(only if needed) with some more context below.\\n\"\n",
    "    \"------------\\n\"\n",
    "    \"{text}\\n\"\n",
    "    \"------------\\n\"\n",
    "    \"Given the new context, refine the original summary. Make sure to address the list of problems, list of solutions and any following action\"\n",
    "    \"If the context isn't useful, return the original summary.\"\n",
    ")\n",
    "refine_prompt = PromptTemplate(\n",
    "    input_variables=[\"existing_answer\", \"text\"],\n",
    "    template=refine_template,\n",
    ")\n",
    "chain = load_summarize_chain(\n",
    "    llm,\n",
    "    chain_type=\"refine\",\n",
    "    return_intermediate_steps=True,\n",
    "    question_prompt=PROMPT,\n",
    "    refine_prompt=refine_prompt,\n",
    ")\n",
    "chain({\"input_documents\": docs}, return_only_outputs=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
